{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c50278",
   "metadata": {},
   "source": [
    "# Ãœbungen zu Teilchenphysik I\n",
    "## Exercise 03 - EMCal in a nutshell\n",
    "\n",
    "    D. Wong, November 2024                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82039ad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "It is very likely that you will need the following packages, so don't forget to import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "# This is a local module that will be necessary for the sections 2 and 3: it's already provided in this repository\n",
    "import exercise3_utils as ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70f3aa-e25b-4929-b97b-b33325e649d8",
   "metadata": {},
   "source": [
    "<a name='section_1_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 1: Electromagnetic cascades in a calorimeter</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58b527c",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'Arial', sans-serif; font-size: 24px; line-height: 1.5; color: yellow; background-color: black; padding: 20px;\">\n",
    "    <img src=\"https://static1.cbrimages.com/wordpress/wp-content/uploads/2022/05/Darth-Varder-Lightning.jpg?q=50&fit=crop&w=1140&h=&dpr=1.5\" alt=\"Darth Vader\" width=\"300\" style=\"float: left; margin-right: 10px;\">\n",
    "\n",
    "<p style=\"font-size: 34px; font-weight: bold;\">Anakin mastered the dark side â€” and the bright sparks of E&M.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb08dab",
   "metadata": {},
   "source": [
    "An **electromagnetic (EM) shower** is a cascade of particles, including photons, electrons, and positrons, forms when a high-energy electron or photon interacts with dense material and produces a chain of secondary particles. Photons convert into electronâ€“positron pairs, and these charged particles in turn emit bremsstrahlung photons, repeating the process as the shower multiplies and spreads. The cascade continues until particle energies fall below a critical value, where ionization dominates and the shower dies out. In an electromagnetic calorimeter (EMCal), this process is harnessed to measure particle energies: alternating layers of absorber and active material contain and sample the shower, converting the deposited energy into measurable signals. The total signal provides a precise estimate of the incident electron or photonâ€™s energy and impact position, making EM calorimetry a key technique in modern high-energy physics experiments.\n",
    "\n",
    "![EMShower](https://www.aanda.org/articles/aa/full/2003/43/aaINTEGRAL41/img17.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebb60f",
   "metadata": {},
   "source": [
    "<a name='section_1_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.1: EMCal dimension estimation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1176f",
   "metadata": {},
   "source": [
    "**Electromagnetic calorimeters (EMCal)** designed to measure EM showers use high-Z materials to trap the shower. The electrons in the shower produce scintillation light, and the amount of light collected is proportional to the total energy of the incident particles. This makes EMCal ideal for precisely measuring the energy of electrons, positrons and photons.\n",
    "\n",
    "The CMS detector at the LHC uses lead tungstate (PbWO$_4$) as the EMCal material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20c0c4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Calculate the radiation length and critical energy of PbWO$_4$ (its effective atomic number is Z = 68.35)</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f96d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "Z_Pb = 82\n",
    "A_Pb = 207\n",
    "density_Pb = 11.34\n",
    "\n",
    "X_0_Pb = 716.4 * A_Pb / (Z_Pb * (Z_Pb + 1) * math.log(287 / math.sqrt(Z_Pb)))\n",
    "print(f\"The radiation length for Pb is {X_0_Pb} g/cmÂ²\")\n",
    "\n",
    "Z_PbWO4 = 68.35\n",
    "E_c_PbWO4 = 800 / Z_PbWO4\n",
    "print(f\"The critical energy for PbW04 is {E_c_PbWO4} MeV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e95a6",
   "metadata": {},
   "source": [
    "The effective atomic number and Thomsonâ€™s approximation cannot produce a good estimation for the radiation length and the critical energy.\n",
    "\n",
    "Consuld the PDG website (https://pdg.lbl.gov/2024/AtomicNuclearProperties/) to get more precise values for both radiation length and critical energy for PbWO$_4$ (note that lead tungstate is an inorganic scintillator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809505cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Calculate the approximate dimension of PbWO$_4$ crystal (longitudinal depth and transverse width) for a 100 GeV electron </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 100000\n",
    "\n",
    "density = 8.3\n",
    "X_0 = 7.39\n",
    "E_c = 9.64\n",
    "\n",
    "moliere_radius = (21 / E_c) * X_0 / density\n",
    "width = 2 * moliere_radius\n",
    "print(f'The Moliere radius of a shower generated by a {E/1000} GeV electron is {moliere_radius} cm')\n",
    "print(f'The width of a shower generated by a {E/1000} GeV electron is {width} cm')\n",
    "\n",
    "x_max = math.log(E/E_c)/math.log(2)\n",
    "length = x_max * X_0 / density\n",
    "print(f'The x_max of a shower generated by a {E/1000} GeV electron is {length} cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941f5ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Is this a good estimation for EMCal size? CMS EMCal crystals are actually 25 $X_0$ longâ€”why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26522e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to measure the entire electromagnetic shower: to cover the whole shower we need redundancy, otherwise the shower\n",
    "# \"leaks\" outside the crystal and we miss part of it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab1d98",
   "metadata": {},
   "source": [
    "<a name='section_1_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.2: Shape of muon clusters on EMCal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dd64c",
   "metadata": {},
   "source": [
    "For bremsstrahlung process, the energy loss through distance is given by $-\\frac{dE}{dx} \\propto \\frac{Z^2 E}{m_{particle}^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a4fdf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Consider a muon with a momentum of 50 GeV. What is the shape of the shower on an EMCal? How do you expect the energy deposit to be distributed on an EMCal?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1733b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 50 GeV muon is still a MIP. We expect a point-like EMCal with very little energy deposit (narrow peak near 0 GeV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1c2ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Knowing at what energy electrons and positrons start emitting significant bremsstrahlung (what energy?), determine the threshold energy for a muon to emit significant bremsstrahlung in a PbWO$_4$ EMCal.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The energy at which electrons and positrons start emitting significant energy via bremsstrahlung is the critical energy.\n",
    "# Let's consider PbWO4: we already got from PDG that the critical energy for an electron is 9.64 MeV in.\n",
    "muon_mass = 105  # MeV\n",
    "electron_mass = 0.511  # MeV\n",
    "ratio2 = (muon_mass / electron_mass)**2\n",
    "E_c_muon = ratio2 * E_c  # MeV\n",
    "print(f'The critical energy for a muon in PbWO4 is {E_c_muon / 1000} GeV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0066a",
   "metadata": {},
   "source": [
    "<a name='section_1_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.3: Detector proposal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb46def",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Imagine that a few years from now you are a principal investigator. How would you implement the identification of electrons from photons and muons?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrons and muons can be distinguished via an electromagnetic calorimeter.\n",
    "# Electrons and photons look identical in an EMCal: we need a charged particle tracker to find the tracks left by the electrons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce470a2",
   "metadata": {},
   "source": [
    "<a name='section_2_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 2: Calorimetry and reconstruction</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b8b7a",
   "metadata": {},
   "source": [
    "The EMCal at the PHENIX experiment has in total, 2592 towers or channels to read out the energy deposits. The channels are arranged in a (72 x 36) matrix. For more details, please refer to the documentation.\n",
    "\n",
    "Use the following code snippet to read one event from the EMCal simulation:\n",
    "\n",
    "```\n",
    "# Example to obtain EMCal hits\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc  # This converts the energy depositions into GeV\n",
    "```\n",
    "\n",
    "In the rest of the exercise, whenever you are asked to work with the simulated events from the PHENIX EMCal, please remember to always conver the energy depositions as above using `ex3.sfc`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21115aab",
   "metadata": {},
   "source": [
    "<a name='section_2_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.1: Events visualization and distribution</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbc650",
   "metadata": {},
   "source": [
    "The `elmID` is the index of the channel that received an hit and `edep` is the energy deposition measured for a hit in the given channel. To reconstruct the energy of the particle, you need to convert `elmID` into 2D spatial coordinates. Also, the energy deposited in the EMCal should be divided by a sampling fraction constant (`ex3.sfc`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420fb15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Write an algorithm that converts the channel ID into a pair of X and Y coordinates (in cm) according to the geometry of the PHENIX EMCal.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_channels_energies_to_matrix(channels, energies, n_rows=72, n_columns=36):\n",
    "    # This function does not map into spatial coordinates: useful to cross-check the results\n",
    "    shape = (n_rows, n_columns)\n",
    "    matrix = np.zeros(shape, dtype=float)\n",
    "    i_rows, i_columns = np.unravel_index(channels, shape)\n",
    "    matrix[i_rows, i_columns] = energies\n",
    "    return matrix.T\n",
    "\n",
    "\n",
    "def channel_to_spatial_coordinates(channels, n_rows=72, n_columns=36, channel_size=5.535):\n",
    "    shape = (n_rows, n_columns)\n",
    "    i_rows, i_columns = np.unravel_index(channels, shape)\n",
    "    x = (i_rows - n_rows / 2) * channel_size\n",
    "    y = (n_columns / 2 - i_columns) * channel_size\n",
    "    return np.column_stack((x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9237c27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Plot the 2D distribution of all hits in an event according to their X and Y coordinates and their energy deposition. For example, show event 5 from the electron sample.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_energy_matrix(matrix, title=\"EMCal clusters\", color_map=\"viridis\"):\n",
    "    import matplotlib  # noqa\n",
    "    masked_matrix = np.ma.masked_where(matrix == 0, matrix)\n",
    "    cmap = matplotlib.colormaps.get_cmap(color_map)\n",
    "    cmap.set_bad(color='white')\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(masked_matrix, cmap=cmap, aspect='auto')\n",
    "    plt.colorbar(label=\"Energy deposition (GeV)\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"X coordinate (arbitrary units)\")\n",
    "    plt.ylabel(\"Y coordinate (arbitrary units)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_spatial_energy_matrix(coordinates, energies, centroids=None, labels=None, title=\"EMCal clusters\", marker_size_scale=20, color_map=\"viridis\"):\n",
    "    x, y = coordinates[:, 0], coordinates[:, 1]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    scatter = plt.scatter(\n",
    "        x, y,\n",
    "        c=energies,\n",
    "        s=energies * marker_size_scale,\n",
    "        cmap=color_map,\n",
    "        edgecolor=\"k\",\n",
    "        alpha=0.8\n",
    "    )\n",
    "    \n",
    "    plt.colorbar(scatter, label=\"Energy deposition (GeV)\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"X coordinate (cm)\")\n",
    "    plt.ylabel(\"Y coordinate (cm)\")\n",
    "    plt.xlim(-210, 210)\n",
    "    plt.ylim(-105, 105)\n",
    "    plt.grid(True)\n",
    "    plt.axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.axvline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "# Plot without the conversion into spatial coordinates\n",
    "mapped_matrix = map_channels_energies_to_matrix(elmID, edep)\n",
    "plot_simple_energy_matrix(mapped_matrix)\n",
    "# Plot with the conversion into spatial coordinates\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "plot_spatial_energy_matrix(coordinates, edep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26be2f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "What is the measured energy of the particle in event 5 of the electron sample? And what is the distribution of all measured energies in all events of the electron sample?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e772f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The total energy for event 5 is rather trivial:\n",
    "total_energy = np.sum(edep)\n",
    "print(f'The total energy is {total_energy} GeV')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5a490",
   "metadata": {},
   "source": [
    "<a name='section_2_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.2: Cluster properties and moments</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da7d49",
   "metadata": {},
   "source": [
    "After having measured the energy deposited by all the hits in a cluster, it is important to characterize the cluster and determine its properties. We will use the moments of a distribution to do this. Remember that the clusters we are analyzing are basically 2D distributions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e68a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Using *numpy*, implement functions to calculate the mean (geometric center), width ($\\sigma$), standardized skewness and standardized kurtosis for the PHENIX EMCal clusters.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_mean(data):\n",
    "    return np.mean(data)\n",
    "\n",
    "\n",
    "def f_width(data):\n",
    "    return np.std(data, ddof=0)\n",
    "\n",
    "\n",
    "def f_variance(data):\n",
    "    return width(data)**2\n",
    "\n",
    "\n",
    "def f_skewness(data):\n",
    "    n = len(data)\n",
    "    mean = f_mean(data)\n",
    "    width = f_width(data)\n",
    "    skewness = np.sum((data - mean) ** 3) / (n * (width ** 3))\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis(data):\n",
    "    n = len(data)\n",
    "    mean = f_mean(data)\n",
    "    width = f_width(data)\n",
    "    kurtosis = np.sum((data - mean) ** 4) / (n * (width ** 4))\n",
    "    return kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ced72d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize again some events from the electron sample and calculate the moments. Which moments look useful for identifying electrons, and why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8496c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3f9dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "(Optional) Implement functions to calculate skewness and kurtosis without \"standardization\" and compute them for few events. Why do we usually use the standardized versions?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_skewness_raw(data):\n",
    "    n = len(data)\n",
    "    mean = f_mean(data)\n",
    "    width = f_width(data)\n",
    "    skewness = np.sum((data - mean) ** 3) / n\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis_raw(data):\n",
    "    n = len(data)\n",
    "    mean = f_mean(data)\n",
    "    width = f_width(data)\n",
    "    kurtosis = np.sum((data - mean) ** 4) / n\n",
    "    return kurtosis\n",
    "\n",
    "\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_skewness_raw = f_skewness_raw(x)\n",
    "y_skewness_raw = f_skewness_raw(y)\n",
    "print(f'Raw skewness: {x_skewness},{y_skewness}')\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "x_kurtosis_raw = f_kurtosis_raw(x)\n",
    "y_kurtosis_raw = f_kurtosis_raw(y)\n",
    "print(f'Raw kurtosis: {x_kurtosis_raw},{y_kurtosis_raw}')\n",
    "\n",
    "# Since skewness and kurtosis basically compares the behaviour of a distribution w.r.t. a gaussian distribution,\n",
    "# the standardized values provide useful numbers to interpret. If one looks at the \"raw\" kurtosis above:\n",
    "# what 625 means? While 1.5 is easy to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fc926",
   "metadata": {},
   "source": [
    "<a name='section_3_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 3: Calorimetry and clustering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d80be",
   "metadata": {},
   "source": [
    "<a name='section_3_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.1: An homemade K-means clustering algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4614b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize the event 0 from the electron sample and the event 6 from the dielectron sample and then compute the relevant moments. Do they still provide a good description for multi-particle cases? Why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event 0, electron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "\n",
    "# Event 6, dielectron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03da784",
   "metadata": {},
   "source": [
    "For cases with particle gun decays, we can perform clustering to group the hits associated with different secondary particles produced in the decay.\n",
    "\n",
    "To test the clustering algorithms and evaluate if they are implemented correctly, you can use the following method to randomly generate a number of clusters with a given number of hits.\n",
    "\n",
    "```\n",
    "import ex3\n",
    "points = ex3.generate_2d_points()\n",
    "# ex3.generate_2d_points(num_clusters=X, points_per_cluster=Y, spread=Z, random_seed=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721df28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Generate some points with the default settings (without passing arguments) and also with some custom settings and visualize the generated datasets.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_points(num_clusters, points_per_cluster, spread, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    data = []\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        center = np.random.uniform([-120, -60], [120, 60])\n",
    "        cluster_points = center + np.random.randn(points_per_cluster, 2) * spread\n",
    "        data.append(cluster_points)\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_constant_array(array, constant=1):\n",
    "    return np.full(array.shape[0], constant)\n",
    "\n",
    "\n",
    "i=0\n",
    "for n in [2, 4, 6]:\n",
    "    for p in [10, 20, 30]:\n",
    "        for s in [1., 3., 5.]:\n",
    "            i+=1\n",
    "            coordinates = generate_2d_points(num_clusters=n, points_per_cluster=p, spread=s, random_seed=i)\n",
    "            energies = get_constant_array(array=coordinates, constant=1)\n",
    "            plot_spatial_energy_matrix(coordinates=coordinates, energies=energies, title=f'Clusters: {n}, Points per clusters: {p}, Spread: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b267cd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ§© K-Means Clustering\n",
    "\n",
    "## What is Cluster Analysis?\n",
    "\n",
    "Cluster analysis is the process of **grouping together similar points into clusters**.\n",
    "A *point* can have 2, 3, or even hundreds of dimensions â€” meaning itâ€™s a vector in some space.\n",
    "\n",
    "One practical example is **epidemiological clustering**:\n",
    "you might have 2D points representing the **longitude and latitude** of locations where birds carrying different strains of avian flu were found.\n",
    "By clustering these points, you can gain insight into which regions correspond to each strain.\n",
    "\n",
    "---\n",
    "\n",
    "## Distances Between Points\n",
    "\n",
    "To cluster data, we must measure **how close or far** points are from each other.\n",
    "The **Euclidean distance** is the most common measure.\n",
    "\n",
    "For two 2D points:\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2}\n",
    "]\n",
    "\n",
    "For two 3D points:\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2 + (p_z - q_z)^2}\n",
    "]\n",
    "\n",
    "In general, for two ( n )-dimensional points\n",
    "( p = (p_1, p_2, â€¦, p_n) ) and ( q = (q_1, q_2, â€¦, q_n) ):\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2}\n",
    "]\n",
    "\n",
    "**Example:**\n",
    "[\n",
    "p = (0.1, 0.2, 0.3, 0.4), \\quad q = (0.0, 0.2, 0.3, 0.2)\n",
    "]\n",
    "[\n",
    "d(p, q) = \\sqrt{(0.1-0.0)^2 + (0.2-0.2)^2 + (0.3-0.3)^2 + (0.4-0.2)^2} = 0.7071â€¦\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "## Cluster Centroids\n",
    "\n",
    "The **centroid** of a cluster is its *center of mass* â€” the **average position** of all points in that cluster.\n",
    "\n",
    "Even though itâ€™s the mean of all cluster points, the centroid does **not** need to be one of those points.\n",
    "\n",
    "To compute a centroid:\n",
    "[\n",
    "\\text{centroid} = \\frac{1}{N} \\sum_{i=1}^{N} p_i\n",
    "]\n",
    "\n",
    "For points:\n",
    "[\n",
    "p + q = (p_1 + q_1, p_2 + q_2, â€¦, p_n + q_n)\n",
    "]\n",
    "and dividing by a scalar ( a ):\n",
    "[\n",
    "\\frac{p}{a} = \\left(\\frac{p_1}{a}, \\frac{p_2}{a}, â€¦, \\frac{p_n}{a}\\right)\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "## The K-Means Algorithm\n",
    "\n",
    "The **idea** behind K-Means is simple:\n",
    "each point belongs to the cluster whose centroid (mean) it is **closest** to.\n",
    "\n",
    "However, because centroids depend on which points are assigned to them, and the assignments depend on the centroids â€” we solve this **chicken-and-egg** problem iteratively.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1. Pick ( k ) Centroids\n",
    "\n",
    "We start by choosing ( k ), the number of clusters we want.\n",
    "\n",
    "Each centroid ( m_j ) is an ( n )-dimensional point:\n",
    "[\n",
    "m_j = (m_{j,1}, m_{j,2}, â€¦, m_{j,n})\n",
    "]\n",
    "\n",
    "We randomly select ( k ) points from the dataset as our **initial centroids**.\n",
    "This is known as the **Forgy Method**, and is one of the most common ways to initialize k-means.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2. Partition the Dataset\n",
    "\n",
    "Each point is assigned to the **nearest centroid** based on Euclidean distance.\n",
    "\n",
    "If a point is equally close to two or more centroids, we break ties arbitrarily (usually by index order).\n",
    "\n",
    "This produces ( k ) sets ( S_1, S_2, â€¦, S_k ),\n",
    "where each set ( S_j ) contains all points closest to centroid ( m_j ).\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3. Recompute the Means\n",
    "\n",
    "For each cluster ( S_j ), we recompute its centroid (mean):\n",
    "[\n",
    "m_j = \\frac{1}{|S_j|} \\sum_{q \\in S_j} q\n",
    "]\n",
    "\n",
    "That is, we take the average of all points assigned to that cluster.\n",
    "\n",
    "Since centroids have changed, some points may now be closer to a different centroid â€”\n",
    "so we **repeat the assignment step**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4. Repeat Until Convergence\n",
    "\n",
    "We alternate between **assigning points** and **recomputing centroids** until:\n",
    "\n",
    "* The centroids stop moving, or\n",
    "* The assignments no longer change.\n",
    "\n",
    "This means the algorithm has **converged**.\n",
    "\n",
    "Sometimes convergence takes too long (many iterations).\n",
    "Therefore, we often set a **maximum iteration limit** to prevent infinite loops.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of the K-Means Algorithm\n",
    "\n",
    "1. Choose ( k ) and initialize centroids randomly.\n",
    "2. Assign each point to the nearest centroid.\n",
    "3. Recompute each centroid as the mean of its assigned points.\n",
    "4. Repeat steps 2â€“3 until centroids stop changing or max iterations reached.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Key Idea:**\n",
    "K-Means minimizes the **within-cluster sum of squared errors (inertia)** â€”\n",
    "that is, the total squared distance between points and their assigned centroids.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to add a small **Matplotlib visualization example** at the end of this Markdown (e.g., showing how centroids move across iterations on a 2D dataset)?\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Minimal NumPy-only K-Means with functionized steps.\n",
    "    No sklearn, no typing â€” pure Python version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "        Number of clusters (K).\n",
    "    init : {\"k-means++\", \"random\"}\n",
    "        Initialization scheme.\n",
    "    max_iter : int\n",
    "        Maximum iterations.\n",
    "    tol : float\n",
    "        Convergence tolerance on centroid shift (Euclidean norm).\n",
    "    random_state : int or None\n",
    "        Seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=None):\n",
    "        self.n_clusters = int(n_clusters)\n",
    "        self.init = init\n",
    "        self.max_iter = int(max_iter)\n",
    "        self.tol = float(tol)\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Attributes set after fitting\n",
    "        self.cluster_centers_ = None\n",
    "        self.labels_ = None\n",
    "        self.inertia_ = None\n",
    "        self.n_iter_ = None\n",
    "\n",
    "    # ---------- core primitives ----------\n",
    "\n",
    "    def _euclidean_squared(self, a, b):\n",
    "        \"\"\"\n",
    "        Squared Euclidean distances between rows of a (n_samples, d)\n",
    "        and rows of b (n_centroids, d). Returns (n_samples, n_centroids).\n",
    "        \"\"\"\n",
    "        a2 = np.sum(a * a, axis=1, keepdims=True)\n",
    "        b2 = np.sum(b * b, axis=1)\n",
    "        ab = a @ b.T\n",
    "        return a2 - 2.0 * ab + b2\n",
    "    \n",
    "    \n",
    "    def _kmeanspp_init(self, X, rng):\n",
    "        \"\"\"\n",
    "        k-means++ initialization. Returns (K, d) array of initial centroids.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        centroids = np.empty((self.n_clusters, n_features), dtype=X.dtype)\n",
    "\n",
    "        # 1) choose first centroid uniformly\n",
    "        idx0 = rng.integers(0, n_samples)\n",
    "        centroids[0] = X[idx0]\n",
    "\n",
    "        # 2) choose remaining with probability proportional to D^2\n",
    "        closest_dist_sq = self._euclidean_squared(X, centroids[0:1]).ravel()\n",
    "        for i in range(1, self.n_clusters):\n",
    "            probs = closest_dist_sq / closest_dist_sq.sum()\n",
    "            idx = rng.choice(n_samples, p=probs)\n",
    "            centroids[i] = X[idx]\n",
    "            d2 = self._euclidean_squared(X, centroids[i:i+1]).ravel()\n",
    "            closest_dist_sq = np.minimum(closest_dist_sq, d2)\n",
    "        return centroids\n",
    "\n",
    "    # ---------- step-by-step methods ----------\n",
    "    #rng = np.random.default_rng(42)\n",
    "    def _initialize_centroids(self, X, rng=None):\n",
    "        \"\"\"Step 2: Initialize centroids randomly.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        # Set Python random seed if random_state was provided\n",
    "        if self.random_state is not None:\n",
    "            random.seed(self.random_state)\n",
    "        # Choose unique random indices for centroids\n",
    "        indices = random.sample(range(n_samples), self.n_clusters)\n",
    "        centroids = X[indices].copy()\n",
    "        return centroids\n",
    "\n",
    "    def _assign(self, X, centroids):\n",
    "        \"\"\"Step 3: Assignment â€” return (labels, d2).\"\"\"\n",
    "        d2 = self._euclidean_squared(X, centroids)\n",
    "        labels = np.argmin(d2, axis=1)\n",
    "        return labels, d2\n",
    "\n",
    "    def _update(self, X, labels, rng):\n",
    "        \"\"\"Step 4: Update â€” compute new centroids, handle empty clusters by re-seeding.\"\"\"\n",
    "        K, d = self.n_clusters, X.shape[1]\n",
    "        new_centroids = np.empty((K, d), dtype=float)\n",
    "        for j in range(K):\n",
    "            mask = (labels == j)\n",
    "            if np.any(mask):\n",
    "                new_centroids[j] = X[mask].mean(axis=0)\n",
    "            else:\n",
    "                # reinitialize empty cluster to a random point\n",
    "                new_centroids[j] = X[rng.integers(0, X.shape[0])]\n",
    "        return new_centroids\n",
    "\n",
    "    def _converged(self, old_centroids, new_centroids, old_labels, new_labels):\n",
    "        \"\"\"Step 5: Convergence check â€” label stability OR centroid shift < tol.\"\"\"\n",
    "        if old_labels is not None and np.array_equal(old_labels, new_labels):\n",
    "            return True\n",
    "        shift = float(np.sqrt(np.sum((new_centroids - old_centroids) ** 2)))\n",
    "        return shift < self.tol\n",
    "\n",
    "    def _compute_inertia(self, X, labels, centroids):\n",
    "        \"\"\"Step 6: Inertia (within-cluster SSE).\"\"\"\n",
    "        return float(np.sum((X - centroids[labels]) ** 2))\n",
    "\n",
    "    # ---------- public API ----------\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Run K-Means on X.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        centroids = self._initialize_centroids(X, rng)\n",
    "        labels = None\n",
    "\n",
    "        for it in range(1, self.max_iter + 1):\n",
    "            new_labels, _ = self._assign(X, centroids)\n",
    "            new_centroids = self._update(X, new_labels, rng)\n",
    "\n",
    "            if self._converged(centroids, new_centroids, labels, new_labels):\n",
    "                centroids = new_centroids\n",
    "                labels = new_labels\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "            labels = new_labels\n",
    "\n",
    "        # Final metrics\n",
    "        inertia = self._compute_inertia(X, labels, centroids)\n",
    "\n",
    "        # Set attributes\n",
    "        self.cluster_centers_ = centroids\n",
    "        self.labels_ = labels\n",
    "        self.inertia_ = inertia\n",
    "        self.n_iter_ = it\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Assign cluster indices for new samples using fitted centroids.\n",
    "        \"\"\"\n",
    "        if self.cluster_centers_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted. Call .fit(X) first.\")\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        labels, _ = self._assign(X, self.cluster_centers_)\n",
    "        return labels\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Convenience: fit the model and return labels for X.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df5cd0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 1:</strong> \n",
    "use the cell below to evalue inertia and iterations K-Means you have implemented</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ---- Load Iris dataset ----\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "# ---- Your implementation ----\n",
    "my_km = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=34)\n",
    "my_labels = my_km.fit_predict(X)\n",
    "\n",
    "print(\"=== Your KMeans ===\")\n",
    "print(f\"Iterations: {my_km.n_iter_}\")\n",
    "print(f\"Inertia: {my_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, my_labels):.4f}\")\n",
    "\n",
    "# ---- scikit-learn implementation ----\n",
    "sk_km = SKKMeans(n_clusters=3, init=\"k-means++\", n_init=1, max_iter=300, tol=1e-4,\n",
    "                 algorithm=\"lloyd\", random_state=42)\n",
    "sk_labels = sk_km.fit_predict(X)\n",
    "\n",
    "print(\"\\n=== scikit-learn KMeans ===\")\n",
    "print(f\"Iterations: {sk_km.n_iter_}\")\n",
    "print(f\"Inertia: {sk_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, sk_labels):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8f83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 2:</strong> \n",
    "Import the external unit test, check if home-brewed K-Means has passed all the test</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i unit_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37abc2d",
   "metadata": {},
   "source": [
    "<a name='section_3_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.2: Finding optimal number of centroids</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9947f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Implement by yourself an elbow method for your K-means algorithm and test it on few events to evaluate its performance.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a268a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(data, score_method, title_label, min_k=1, max_k=10):\n",
    "    score_values = []\n",
    "\n",
    "    for k in range(min_k, max_k + 1):\n",
    "        centroids, labels = k_means(data, k)\n",
    "        score = score_method(data, centroids, labels)\n",
    "        energies = get_constant_array(data)\n",
    "        plot_spatial_energy_matrix_complex(data, energies, centroids=centroids, labels=labels, title=f'{title_label} - Clusters: {k} - Score: {score}')\n",
    "        score_values.append(score)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(range(min_k, max_k + 1), score_values, marker='o', linestyle='--')\n",
    "    plt.title(f\"{title_label} method for the optimal K\")\n",
    "    plt.xlabel(\"Number of clusters (K)\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def wcss_score(data, centroids, labels):\n",
    "    wcss = 0\n",
    "    k = len(centroids)\n",
    "    for i in range(k):\n",
    "        cluster_points = data[labels == i]\n",
    "        centroid = centroids[i]\n",
    "        squared_distances = np.sum((cluster_points - centroid) ** 2, axis=1)\n",
    "        wcss += np.sum(squared_distances)\n",
    "    return wcss\n",
    "\n",
    "\n",
    "for n in [2, 4, 6]:\n",
    "    print('###############################################################################################')\n",
    "    print(f'Generating {n} clusters...')\n",
    "    coordinates = generate_2d_points(num_clusters=n, points_per_cluster=20, spread=4., random_seed=999)\n",
    "    evaluate_method(data=coordinates, score_method=wcss_score, title_label='Elbow method', min_k=2, max_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d95e60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Implement by yourself a silhouette method for your K-means algorithm and test it on few events to evaluate its performance.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(data, centroids, labels):\n",
    "    total_score = 0\n",
    "    n_samples = data.shape[0]\n",
    "    k = len(centroids)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        point = data[i]\n",
    "        point_label = labels[i]\n",
    "\n",
    "        # Calculate the intra-cluster distance a_i\n",
    "        same_cluster_points = data[labels == point_label]\n",
    "        intra_cluster_distances = np.sum((same_cluster_points - point) ** 2, axis=1)\n",
    "        a_i = np.sum(intra_cluster_distances) / len(same_cluster_points)\n",
    "\n",
    "        # Calculate the nearest cluster distance b_i\n",
    "        # Calculate the nearest cluster distance b_i\n",
    "        b_i = float('inf')\n",
    "        for j in range(k):\n",
    "            if j == point_label:\n",
    "                continue  # Skip the same cluster\n",
    "            other_cluster_points = data[labels == j]\n",
    "            inter_cluster_distances = np.sum((other_cluster_points - point) ** 2, axis=1)\n",
    "            nearest_cluster_distance = np.sum(inter_cluster_distances) / len(other_cluster_points)\n",
    "            if nearest_cluster_distance < b_i:\n",
    "                b_i = nearest_cluster_distance\n",
    "\n",
    "        # Calcualte the silhouette hit score s_i\n",
    "        #if np.isinf(a_i) or np.isinf(b_i):\n",
    "        #    s_i = 0\n",
    "        if max(a_i, b_i) == 0:\n",
    "            s_i = 0\n",
    "        else:\n",
    "            s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        total_score += s_i\n",
    "\n",
    "    # Return the average silhouette score S of the event\n",
    "    return total_score / n_samples\n",
    "\n",
    "\n",
    "for n in [2, 4, 6]:\n",
    "    print('###############################################################################################')\n",
    "    print(f'Generating {n} clusters...')\n",
    "    coordinates = generate_2d_points(num_clusters=n, points_per_cluster=20, spread=4., random_seed=999)\n",
    "    evaluate_method(data=coordinates, score_method=silhouette_score, title_label='Silhouette method', min_k=2, max_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02eb580",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "comparison of computational complexity for elbow and silhouette</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdaf101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f62e35",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "For particle physics, what tricks you can come up to reduce the computation complexity of number and coordination for the centroids</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_search(channels, energies, min_energy_threshold=5.0, padding_size=1, n_rows=72, n_columns=36):\n",
    "    # Step 1: Map energies to the 2D energy matrix\n",
    "    energy_matrix = map_channels_energies_to_matrix(channels, energies, n_rows, n_columns)\n",
    "\n",
    "    # Step 2: Apply minimum energy threshold to identify potential seed candidates\n",
    "    # Creating a binary mask where energy values are greater than the threshold\n",
    "    energy_mask = energy_matrix > min_energy_threshold\n",
    "\n",
    "    # Step 3: Get the coordinates of the potential seeds\n",
    "    seed_coordinates = np.argwhere(energy_mask)\n",
    "\n",
    "    # Step 4: Sort seeds by their energy values (ascending)\n",
    "    seed_energies = energy_matrix[energy_mask]\n",
    "    sorted_seeds = sorted(zip(seed_energies, seed_coordinates), key=lambda x: x[0])\n",
    "\n",
    "    # Step 5: Define a padding region and check for neighboring cells with higher energy\n",
    "    valid_seeds = []\n",
    "    for energy, (x, y) in sorted_seeds:\n",
    "        # Create a region around the current seed (including padding)\n",
    "        x_min = max(0, x - padding_size)\n",
    "        x_max = min(n_rows, x + padding_size + 1)\n",
    "        y_min = max(0, y - padding_size)\n",
    "        y_max = min(n_columns, y + padding_size + 1)\n",
    "\n",
    "        # Extract the neighboring region (within bounds)\n",
    "        region = energy_matrix[x_min:x_max, y_min:y_max]\n",
    "\n",
    "        # If any neighboring cell has energy greater than the current seed, discard it\n",
    "        if np.any(region > energy):\n",
    "            continue\n",
    "\n",
    "        # Otherwise, keep this seed\n",
    "        channel_id = y * n_columns + x\n",
    "        valid_seeds.append(channel_id)\n",
    "\n",
    "    if not valid_seeds:\n",
    "        return None\n",
    "\n",
    "    return valid_seeds\n",
    "\n",
    "# This will be evaluated later :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab48d5",
   "metadata": {},
   "source": [
    "<a name='section_3_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.3: Resolution of EM Calorimeter</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cf62e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "---\n",
    "\n",
    "# A) Step-by-step in your current B4b (sampling ECAL) setup\n",
    "\n",
    "1. **Produce runs at several beam energies**\n",
    "   Run `exampleB4b.py` in batch mode for (E={1,2,5,10,20,50},\\text{GeV}) (or your list), saving one ROOT file per energy (youâ€™re already renaming `B4.root` to `B4_<E>GeV.root` after each run).\n",
    "\n",
    "2. **Choose what you call â€œmeasured energyâ€**\n",
    "   For a sampling ECAL the readout is the **active medium**. From each ROOT file read **`Egap`** (energy deposited in the gap) **per event**. Thatâ€™s your event-wise observable (E_{\\text{meas}}).\n",
    "\n",
    "3. **Build the per-energy response**\n",
    "   For each beam energy (E_{\\text{beam}}), make the distribution of (E_{\\text{meas}}) over events.\n",
    "\n",
    "   * Prefer a **Gaussian fit** (mean (\\mu), width (\\sigma)) to the core of the spectrum. If you just take sample mean/std itâ€™s usually fine for clean, symmetric distributions; CMS used a Gaussian + polynomial tail to be robust to low-energy tails. \n",
    "   * Compute the **resolution** (R=\\sigma/\\mu).\n",
    "\n",
    "4. **Fit the resolution curve**\n",
    "   If you did not simulate electronics noise, use the 2-term model\n",
    "   [\n",
    "   R(E)=\\sqrt{\\frac{S^2}{E}+C^2}.\n",
    "   ]\n",
    "   (With no electronics, the (N/E) term is effectively zero.) Fit (S) (stochastic) and (C) (constant).\n",
    "   Tip: Linearize as (R^2 = (S^2),(1/E) + C^2) and do a straight-line fit vs (1/E).\n",
    "\n",
    "5. **Report**\n",
    "   Quote (S) as â€œ(S\\times100%\\cdot\\sqrt{\\text{GeV}})â€ and (C) as a percent. Plot (R(E)) with the fit curve.\n",
    "\n",
    " This matches the **physics meaning** of energy resolution and is fully consistent for your B4b study. What it does **not** include (yet) is CMSâ€™s leakage correction and explicit electronics noise treatment, which are experiment-specific refinements. \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f05af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "# ðŸ§± **B4d Calorimeter Geometry Overview**\n",
    "\n",
    "B4d defines a **longitudinal sampling electromagnetic calorimeter**:\n",
    "a stack of alternating **absorber** and **active (gap)** layers, just like B4b, but with **sensitive detectors** and **scorers** automatically attached.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”© **Geometric parameters (default values)**\n",
    "\n",
    "| Quantity                     | Symbol          | Default Value         | Description                                |\n",
    "| ---------------------------- | --------------- | --------------------- | ------------------------------------------ |\n",
    "| Number of layers             | `nofLayers`     | 10                    | Number of absorber + gap pairs             |\n",
    "| Absorber thickness           | `absoThickness` | 10 mm                 | Thickness of lead absorber per layer       |\n",
    "| Gap (active layer) thickness | `gapThickness`  | 5 mm                  | Thickness of liquid argon gap per layer    |\n",
    "| Calorimeter transverse size  | `calorSizeXY`   | 10 cm Ã— 10 cm         | Square cross-section perpendicular to beam |\n",
    "| World volume size            | `1.2Ã—` larger   | 12 cm Ã— 12 cm Ã— 18 cm | Vacuum surrounding the calorimeter         |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© **Material composition**\n",
    "\n",
    "| Volume          | Material            | Notes                                             |\n",
    "| --------------- | ------------------- | ------------------------------------------------- |\n",
    "| **Absorber**    | `G4_Pb` (lead)      | Dense converter for eâ»/Î³ showers                  |\n",
    "| **Gap**         | `liquidArgon`       | Active readout medium (collects deposited energy) |\n",
    "| **World**       | `Galactic` (vacuum) | Empty container for geometry                      |\n",
    "| **Calorimeter** | (composite)         | Logical container holding 10 layers               |\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ **Structure (Z-axis stacking)**\n",
    "\n",
    "Each layer consists of:\n",
    "\n",
    "```\n",
    "|<--- Layer (15 mm) ----------------------------->|\n",
    "|                                                 |\n",
    "|   [ Absorber (Pb) | 10 mm ]  +  [ Gap (LAr) | 5 mm ] |\n",
    "```\n",
    "\n",
    "Stack 10 such layers along **+z** (the beam direction), producing a total depth of **150 mm**.\n",
    "\n",
    "### Schematic:\n",
    "\n",
    "```\n",
    "  eâ» beam â†’\n",
    "            |##########|-----|##########|-----|##########|-----|\n",
    "            |  Pb (10) | LAr |  Pb (10) | LAr |  Pb (10) | LAr |\n",
    "            |##########|-----|##########|-----|##########|-----|\n",
    "                    <----------- repeated 10 times ----------->\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ **World hierarchy**\n",
    "\n",
    "| Level | Volume name   | Parent        | Description            |\n",
    "| ----- | ------------- | ------------- | ---------------------- |\n",
    "| 0     | `World`       | â€”             | Vacuum box             |\n",
    "| 1     | `Calorimeter` | `World`       | Container of layers    |\n",
    "| 2     | `Layer`       | `Calorimeter` | Replicated 10Ã— along z |\n",
    "| 3     | `Abso`        | `Layer`       | Lead absorber          |\n",
    "| 3     | `Gap`         | `Layer`       | Liquid argon gap       |\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ§  **Physical meaning**\n",
    "\n",
    "* **Absorber (Pb):** Converts incident eâ» or Î³ into a cascade of secondary particles via bremsstrahlung and pair production.\n",
    "* **Gap (LAr):** Collects the energy deposits of the shower particles; this â€œvisible energyâ€ is your calorimeter signal.\n",
    "* Each layer combination corresponds to one **sampling unit**.\n",
    "* Total thickness (~150 mm) gives about **15 radiation lengths**, enough to contain a several-GeV electromagnetic shower.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, shutil, pathlib, textwrap, os\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- CONFIG ----\n",
    "EXE = \"exampleB4d.py\"     # <- use the B4d example\n",
    "N_EVENTS = 100           # bump stats for smoother Ïƒ/E\n",
    "energies_GeV = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "# ---- RUN ONE ENERGY AND RENAME OUTPUT ----\n",
    "def run_one_energy(E):\n",
    "    mac = pathlib.Path(f\"run_{E}GeV.mac\")\n",
    "    mac.write_text(textwrap.dedent(f\"\"\"\n",
    "        /run/initialize\n",
    "        /gun/particle e-\n",
    "        /gun/energy {E} GeV\n",
    "        /run/printProgress 1000\n",
    "        /run/beamOn {N_EVENTS}\n",
    "    \"\"\").strip())\n",
    "\n",
    "    # ensure no leftover file from previous run\n",
    "    if pathlib.Path(\"B4.root\").exists():\n",
    "        os.remove(\"B4.root\")\n",
    "\n",
    "    # run the example in batch mode with this macro\n",
    "    subprocess.run([\"python\", EXE, \"-m\", str(mac)], check=True)\n",
    "\n",
    "    # the example writes B4.root; rename to per-energy file\n",
    "    src = pathlib.Path(\"B4.root\")\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(\"Expected B4.root not found. Did the run finish?\")\n",
    "    dst = pathlib.Path(f\"B4_{E}GeV.root\")\n",
    "    shutil.move(str(src), str(dst))\n",
    "    return str(dst)\n",
    "\n",
    "# run all energies\n",
    "roots = [run_one_energy(E) for E in energies_GeV]\n",
    "print(\"Wrote:\", roots)\n",
    "\n",
    "# ---- LOAD Edep IN GAP (VISIBLE ENERGY) ----\n",
    "def load_edep_gap(root_path):\n",
    "    with uproot.open(root_path) as f:\n",
    "        t = f[\"B4\"]                    # TTree name\n",
    "        Egap = t[\"Egap\"].array(library=\"np\")  # MeV\n",
    "    return Egap\n",
    "\n",
    "means, sigmas, resolutions = [], [], []\n",
    "for E, rfile in zip(energies_GeV, roots):\n",
    "    Egap = load_edep_gap(rfile)       # MeV per event\n",
    "    mu   = Egap.mean()                # MeV\n",
    "    sig  = Egap.std(ddof=1)           # MeV\n",
    "    R    = sig / mu                   # dimensionless\n",
    "    means.append(mu)\n",
    "    sigmas.append(sig)\n",
    "    resolutions.append(R)\n",
    "\n",
    "means  = np.array(means)\n",
    "sigmas = np.array(sigmas)\n",
    "R      = np.array(resolutions)\n",
    "E      = np.array(energies_GeV, dtype=float)\n",
    "\n",
    "# ---- FIT R(E) = sqrt(a^2/E + b^2) VIA LINEARIZATION ----\n",
    "x = 1.0 / E\n",
    "y = R**2\n",
    "A = np.vstack([x, np.ones_like(x)]).T\n",
    "m, c = np.linalg.lstsq(A, y, rcond=None)[0]  # y â‰ˆ m x + c\n",
    "a = float(np.sqrt(max(m, 0.0)))  # stochastic term (âˆšGeV units)\n",
    "b = float(np.sqrt(max(c, 0.0)))  # constant term\n",
    "\n",
    "print(f\"a = {a*100:.1f}%Â·âˆšGeV\")\n",
    "print(f\"b = {b*100:.2f}%\")\n",
    "\n",
    "# ---- PLOT ----\n",
    "E_dense = np.linspace(E.min(), E.max(), 200)\n",
    "R_fit = np.sqrt( (a*a)/E_dense + b*b )\n",
    "\n",
    "plt.plot(E, R, \"o\", label=\"data (Ïƒ/âŸ¨EâŸ©)\")\n",
    "plt.plot(E_dense, R_fit, \"-\", label=f\"fit: a={a*100:.1f}%âˆšGeV, b={b*100:.2f}%\")\n",
    "plt.xlabel(\"Beam energy E (GeV)\")\n",
    "plt.ylabel(\"Energy resolution Ïƒ/âŸ¨EâŸ©\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1aaeb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Belle2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
