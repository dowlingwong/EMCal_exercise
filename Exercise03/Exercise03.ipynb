{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c50278",
   "metadata": {},
   "source": [
    "# Exercises for Particle Physics I\n",
    "## Exercise 03 - EMCal in a nutshell\n",
    "\n",
    "    D. Wong, November 2025                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82039ad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "It is very likely that you will need the following packages, so don't forget to import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a local module that will be necessary for the sections 2 and 3: it's already provided in this repository\n",
    "import exercise3_utils as ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70f3aa-e25b-4929-b97b-b33325e649d8",
   "metadata": {},
   "source": [
    "<a name='section_1_0'></a>\n",
    "\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 1: Electromagnetic cascades in a calorimeter</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb08dab",
   "metadata": {},
   "source": [
    "An **electromagnetic (EM) shower** is a cascade of particles, including photons, electrons, and positrons, forms when a high-energy electron or photon interacts with dense material and produces a chain of secondary particles. <br>\n",
    "Photons convert into electron‚Äìpositron pairs, and these charged particles in turn emit bremsstrahlung photons, repeating the process as the shower multiplies and spreads. <br>\n",
    "The cascade continues until particle energies fall below a critical value, where ionization dominates and the shower dies out. <br>\n",
    "In an electromagnetic calorimeter (EMCal), this process is harnessed to measure particle energies, where the deposited energy is converted into measurable signals (e.g., light). <br>\n",
    "The total signal provides a precise estimate of the incident electron or photon‚Äôs energy and impact position, making EM calorimetry a key technique in modern high-energy physics experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4314fc-7782-45d0-b4d5-ffcd3ebe7988",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/x0.png\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Development of an electromagnetic shower </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b0a4b-ffff-40d7-a8d4-94211a460f9f",
   "metadata": {},
   "source": [
    "Bremsstrahlung is the primary energy loss process for electrons/positrons above ( $\\sim$ 10 )~MeV, while photons lose energy mainly through the production of electron‚Äìpositron pairs.\n",
    "High-energy photons, electrons, and positrons create a cascade of secondary particles‚Äîknown as an ‚Äúelectromagnetic shower.‚Äù\n",
    "\n",
    "The following quantities ($\\textit{Thomson‚Äôs approximation}$) are defined:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c5543-e1ef-446f-b612-debf15ea52c7",
   "metadata": {},
   "source": [
    "- $\\textbf{Radiation Length} ~X_0$: Average distance over which the electron energy reduces by 1/e:\n",
    "    \n",
    "    $$ X_0 \\approx \\frac{1}{4 \\, \\alpha \\, n \\, Z^2 \\, r_e^2 \\ln \\left( \\frac{287}{\\sqrt{Z}} \\right)} $$\n",
    "  \n",
    "    where $\\alpha$ is the fine-structure constant, $n$ is the number density of the nucleus, $Z$ is the atomic number of the nucles, and $r_e$ is the classical electron radius.\n",
    "\n",
    "- $\\textbf{Critical Energy} ~E_c$: Energy at which ionization becomes the dominant energy loss:\n",
    "    \n",
    "    $$ E_c \\approx \\frac{800\\text{MeV}}{Z} $$\n",
    "  \n",
    "\n",
    "- $\\textbf{Moli√®re Radius} ~R_M$: Represents the lateral spread of an electromagnetic shower, mainly due to multiple scattering:\n",
    "    \n",
    "    $$ R_M = \\frac{21 \\, \\text{MeV}}{E_c}  X_0 \\, (\\text{g/cm}^2) $$\n",
    "    \n",
    "    Approximately 95% of the shower energy is contained within $2 R_M$ (transverse width).\n",
    "\n",
    "- $\\textbf{Maximum Particle Count Length} ~x_{\\text{max}}$: The shower reaches the maximum particle count after $x_{\\text{max}}$ radiation lengths, given by:\n",
    "    \n",
    "    $$ x_{\\text{max}} = \\frac{\\ln(E / E_c)}{\\ln 2} X_0 $$\n",
    "  \n",
    "    where $E$ is the initial energy, and $x_{\\text{max}}$ is also called longitudinal depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6153ac2-69f8-41e7-812e-88d965062745",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/e_eng_loss.png\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Electron energy loss as a function of the energy </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebb60f",
   "metadata": {},
   "source": [
    "<a name='section_1_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.1: EMCal dimension estimation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1176f",
   "metadata": {},
   "source": [
    "**Electromagnetic calorimeters (EMCal)** are designed to measure the energy of particles using high-Z materials to trap the shower. \n",
    "\n",
    "The electrons in the shower produce scintillation light, and the amount of light collected is proportional to the total energy of the incident particles. This makes EMCal ideal for precisely measuring the energy of electrons, positrons, and photons.\n",
    "\n",
    "The CMS detector at the LHC uses lead tungstate (PbWO$_4$) as the EMCal material.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Rosalinde-Pots/publication/364997605/figure/fig3/AS:11431281094130646@1667393809224/Schematic-overview-of-the-Electromagnetic-Calorimeter-ECAL-of-CMS-Modified-from-32.jpg\" \n",
    "alt=\"CMS ECAL\"\n",
    "width=\"600\" \n",
    "style= \"display:block; margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130344ef-cfa8-4e81-aa38-d1b007a91da3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Calculate the radiation length and critical energy of Pb and PbWO$_4$. Then, compare your results with those available on the PDG website: <br>\n",
    "- Pb: <a href=\"https://pdg.lbl.gov/2024/AtomicNuclearProperties/HTML/lead_Pb.html\">link</a><br>\n",
    "- PbWO4: <a href=\"https://pdg.lbl.gov/2024/AtomicNuclearProperties/HTML/lead_tungstate.html\">link</a><br>\n",
    "<br>\n",
    "\n",
    "For PbWO$_4$, assume an effective atomic number Z = $\\dfrac{Z_{Pb} + Z_W + 4 \\times Z_O}{6}$ = $\\dfrac{82 + 74 + 4 \\times 8}{6}$ = 31.3 <br>\n",
    "and an effective atomic weigth A = $\\dfrac{A_{Pb} + A_W + 4 \\times A_O}{6}$ = $\\dfrac{207.2 + 183.8 + 4 \\times 16}{6}$ = 75.8 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Do your calculated values correspond to what you found in the PDG page?\n",
    "\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2b96f-ae38-4d56-ae61-6379136af364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code. \n",
    "\n",
    "def critical_energy(..., ..., ...):\n",
    "    return ... # fill with formula\n",
    "\n",
    "def radiation_length(..., ..., ...):\n",
    "    return ... # fill with formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9ad2b-9965-4d8f-a6f6-259cc5a16aa8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e95a6",
   "metadata": {},
   "source": [
    "The effective atomic number and Thomson's approximation cannot produce a good estimation for the radiation length and the critical energy.\n",
    "\n",
    "Consult the PDG [website](https://pdg.lbl.gov/2024/AtomicNuclearProperties/) to get more precise values for both radiation length and critical energy for PbWO$_4$ (note that lead tungstate is an inorganic scintillator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809505cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Estimate the approximate dimension of an electromagnetic shower in a PbWO$_4$ crystal (longitudinal depth and transverse width) for a 100 GeV electron. \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to estimate the shower depth and width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941f5ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Is this a good estimation for the size an EMCal should have? The CMS EMCal crystals are actually 25 $X_0$ long: why? </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea7610-a6ca-4803-b015-834d5a437cf3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab1d98",
   "metadata": {},
   "source": [
    "<a name='section_1_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.2: Shape of muon clusters on EMCal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b1749-9632-4d27-8866-85c0a8051fba",
   "metadata": {},
   "source": [
    "For muons with energies of the order of 100 GeV, the ionization is the dominant energy-loss process. <br>\n",
    "Muons travel significant distances in dense materials: for example, a 10 GeV muon loses about 10 MeV/cm in iron and has a range of several meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674bcce-123e-4a92-b060-cf61614b7e11",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/mu_eng_loss.png\" width=\"50%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad892256-e723-4e4d-9723-ab91c0672ec3",
   "metadata": {},
   "source": [
    "A particle with a momentum close to the minimum ionization point is called a minimum ionizing particle (MIP). <br>\n",
    "A particle with a much larger momentum but with an energy loss comparable to that of the minimum ionization point is also called a MIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dd64c",
   "metadata": {},
   "source": [
    "For bremsstrahlung process, the energy loss through distance is given by: \n",
    "\n",
    "$-\\dfrac{dE}{dx} \\propto \\dfrac{Z^2 E}{m_{particle}^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a4fdf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Consider a muon with a momentum of 50 GeV passing through the CMS EMCal, which has a depth of approximately 22 cm. What is the shape of the shower you expect? How do you expect the energy deposit to be distributed?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02f843-d4b2-4f88-8dfc-55827049b330",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1c2ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Knowing at what energy electrons and positrons start emitting significant bremsstrahlung (how is this transition energy called?), determine the threshold energy for a muon to emit significant bremsstrahlung in a PbWO$_4$ EMCal. \n",
    "In other words, what energy must a muon possess to deposit an amount of evenrgy equal to the critical energy?\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6bb5c-d72d-40ec-be76-180038464236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code \n",
    "\n",
    "# The energy at which electrons and positrons start emitting significant energy via bremsstrahlung is the critical energy.\n",
    "# Let's consider PbWO4: we already got from PDG that the critical energy for an electron is 9.64 MeV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0066a",
   "metadata": {},
   "source": [
    "<a name='section_1_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.3: Detector proposal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb46def",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "How would you implement an experimental apparatus involving an EMCal so that it can distinguish electrons from photons and muons?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b79226-6388-4b7e-bf56-913d7dfe8b3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce470a2",
   "metadata": {},
   "source": [
    "<a name='section_2_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 2: Calorimetry and reconstruction</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b8b7a",
   "metadata": {},
   "source": [
    "In this section, we will consider a real EMCal, used in the [PHENIX](https://www.phenix.bnl.gov/) experiment at Brookhaven National Laboratory.\n",
    "\n",
    "We have prepared ROOT n-tuples containing hit information from the EMCal, using a particle gun with a gaussian energy distribution, ranging from 5 GeV to 80 GeV.\n",
    "\n",
    "The EMCal at the PHENIX experiment covers an area of $2~m~\\times~4~m$ perpendicular to the beamline. \n",
    "\n",
    "This corresponds to 3 √ó 6 EMCal super modules where:\n",
    "- 1 EMCal super module = 6 √ó 6 = 36 EMCal modules.\n",
    "- 1 EMCal module is 11 cm √ó 11 cm and contains 2 √ó 2 = 4 towers/channels, with a granularity of approximately 5.5 cm.\n",
    "\n",
    "In total, there are 2592 towers or channels to read out the energy deposits from the EMCal.\n",
    "\n",
    "For practical purposes, consider the PHENIX EMCal as a 2D matrix of 2592 channels (72 horizontal x 36 vertical), where each channel has a dimension of (5.535cm x 5.535cm x 36.96cm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd0329-4db4-465f-b450-0f65d496cae6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/PHENIX_color_view.gif\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Schematic view of the PHENIX detector. </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b4dcb-402d-4cd9-b904-71bc9459e87b",
   "metadata": {},
   "source": [
    "We provide rootfiles containing the readout for electron and dielectron events from the EMCal.\n",
    "\n",
    "The readout has the following format:\n",
    "```\n",
    "'elmID': array([1207, 1208, 1243, 1244, 1245, 1246, 1279, 1280, 1281, 1282,\n",
    "       1283, 1314, 1315, 1316, 1317, 1318, 1352, 1387, 1388, 1389, 1390],\n",
    "       dtype=int32), \n",
    "'edep': array([2.1672759e-03, 2.3865167e-03, 6.9637364e-03, 6.5519638e-02,\n",
    "       5.9960117e-03, 1.5223619e-03, 1.5519783e-02, 1.3763729e+00,\n",
    "       1.7959915e-02, 1.1316873e-03, 2.6412117e-03, 1.1183993e-03,\n",
    "       3.0373151e-03, 1.8506199e-02, 5.9680296e-03, 1.2358509e-03,\n",
    "       1.5430434e-03, 1.2675102e-03, 8.8297541e-04, 8.7783835e-04,\n",
    "       1.5175857e-03],\n",
    "       dtype=float32)\n",
    "```\n",
    "\n",
    "where `elmID[X]` is the identifier ($\\textit{element ID}$) of the channel that measured a given $\\textit{energy deposit}$ `edep[X]`.\n",
    "\n",
    "The values of `elmID[X]` vary from 0 to 2591 (corresponding to the total number of channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4be8f-db61-423e-b818-83818a571c47",
   "metadata": {},
   "source": [
    "To conveniently read the rootfiles, we provide the `exercise3_utils.py` module.\n",
    "\n",
    "Use the following code snippet to read one event from the EMCal simulation:\n",
    "\n",
    "```\n",
    "# Example to obtain EMCal hits\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc  # This converts the energy depositions into GeV\n",
    "```\n",
    "\n",
    "When using `elmID, edep = ex3.get_hit_data()`, you will be asked to select which set of simulated events you want to use.\n",
    "We are providing one `electron.root` and one `dieletron.root` samples: digit `electron` or `dieletron` depending on what sample you want to access.\n",
    "\n",
    "In the rest of the exercise, whenever you are asked to work with the simulated events from the PHENIX EMCal, please also remember to always convert the energy depositions as above using `ex3.sfc`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21115aab",
   "metadata": {},
   "source": [
    "<a name='section_2_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.1: Events visualization and distribution</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbc650",
   "metadata": {},
   "source": [
    "As briefly mentioned in the previous section. `elmID` indexes the EMCal tower (channel) where a hit occurred and `edep` is the corresponding deposited energy; to reconstruct the particle energy, you map `elmID` to 2D coordinates in the PHENIX EMCal, treat the detector as a 72 √ó 36 matrix of 2592 towers (each about 5.535 cm √ó 5.535 cm √ó 36.96 cm), and form a small cluster by summing the cell with the maximum deposit and its nearest neighbors, then correct the summed energy by dividing by the sampling-fraction constant `ex3.sfc`; geometrically, the EMCal consists of 3 √ó 6 supermodules, each made of 6 √ó 6 = 36 modules, and each 11 cm √ó 11 cm module contains a 2 √ó 2 array of readout towers.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; gap: 16px; align-items: flex-start; margin-top: 12px;\">\n",
    "\n",
    "  <figure style=\"text-align: center; margin: 0;\">\n",
    "    <img src=\"figures/emcal.png\" alt=\"EMCal layout\" height=\"400\">\n",
    "    <figcaption>EMCal global layout</figcaption>\n",
    "  </figure>\n",
    "\n",
    "  <figure style=\"text-align: center; margin: 0;\">\n",
    "    <img src=\"figures/emcal_1.png\" alt=\"EMCal module structure\" height=\"400\">\n",
    "    <figcaption>EMCal module structure</figcaption>\n",
    "  </figure>\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420fb15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Write an algorithm that converts the channel ID into a pair of X and Y coordinates (in cm) according to the geometry of the PHENIX EMCal.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_channels_energies_to_matrix(channels, energies, n_rows=72, n_columns=36):\n",
    "    '''\n",
    "    This function is not ment to map into spatial coordinates,\n",
    "    but it is useful to cross-check the results.\n",
    "    '''\n",
    "\n",
    "def channel_to_spatial_coordinates(channels, n_rows=72, n_columns=36, channel_size=5.535):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9237c27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Plot the 2D distribution of all hits in an event according to their X and Y coordinates and their energy deposition. For example, show event 5 from the electron sample.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_energy_matrix(matrix, title=\"EMCal clusters\", color_map=\"viridis\"):\n",
    "\n",
    "\n",
    "def plot_spatial_energy_matrix(coordinates, energies, centroids=None, labels=None, title=\"EMCal clusters\", marker_size_scale=20, color_map=\"viridis\"):\n",
    "    \n",
    "\n",
    "\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26be2f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> <br>\n",
    "- What is the measured energy of the particle in event 5 of the electron sample?  <br>\n",
    "- And what is the distribution of all measured energies in all events of the electron sample?  <br>\n",
    "  <strong> Hint </strong>: check 'exercise3_utils.py' to understand how to conveinently access events without the need of keyboard inputs.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e772f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5a490",
   "metadata": {},
   "source": [
    "<a name='section_2_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.2: Cluster properties and moments</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da7d49",
   "metadata": {},
   "source": [
    "After having measured the energy deposited by all the hits in a cluster, it is important to characterize the cluster and determine its properties. We will use the moments of a distribution to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57add0d-e88a-494f-ade7-832750c714d1",
   "metadata": {},
   "source": [
    "The moments of a distribution provide useful information about its shape and spread. Below are the formulas for different moments:\n",
    "- $\\textbf{1st order (raw)}$:\n",
    "    $$\n",
    "    \\text{Mean: } \\mu := \\mathbb{E}[X] = \\frac{\\mu_1}{1}\n",
    "    $$\n",
    "- $\\textbf{2nd order (central)}$:\n",
    "    $$\n",
    "    \\text{Variance: } \\sigma^2 = \\mathbb{E}[(X - \\mu)^2] = \\frac{\\mu_2}{1^2} = \\mu_2\n",
    "    $$\n",
    "- $\\textbf{3rd order (standardized)}$:\n",
    "    $$\n",
    "    \\text{Skewness: }\\gamma = \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right)^3 \\right] = \\frac{\\mathbb{E}[(X - \\mu)^3]}{(\\mathbb{E}[(X - \\mu)^2])^{3/2}}\n",
    "    $$\n",
    "- $\\textbf{4th order (standardized)}$:\n",
    "    $$\n",
    "    \\text{Kurtosis: } g = \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right)^4 \\right] = \\frac{\\mathbb{E}[(X - \\mu)^4]}{(\\mathbb{E}[(X - \\mu)^2])^2}\n",
    "    $$\n",
    "\n",
    "They are helpful to analyze the 2D distribution of the EMCal hits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e68a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Using $\\textit{numpy}$, implement functions to calculate the mean (geometric center), width ($\\sigma$), standardized skewness and standardized kurtosis for the PHENIX EMCal clusters.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to complete the following functions\n",
    "\n",
    "def f_mean(data):\n",
    "    ...\n",
    "    return mean\n",
    "\n",
    "\n",
    "def f_width(data):\n",
    "    ...\n",
    "    return width\n",
    "\n",
    "\n",
    "def f_variance(data):\n",
    "    ...\n",
    "    return variance\n",
    "\n",
    "\n",
    "def f_skewness(data):\n",
    "    ...\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis(data):\n",
    "    ...\n",
    "    return kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ced72d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize again some events from the electron sample and calculate the moments. Which moments look useful for identifying electrons, and why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8496c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1718f-eaf0-44fc-9371-16a4955f745e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3f9dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Standardization means rescaling data so that it has a mean of 0 and a standard deviation of 1.<br><br>\n",
    "Implement functions to calculate skewness and kurtosis without \"standardization\" and compute them for a few events. Why do we usually use the standardized versions?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to complete the following functions\n",
    "\n",
    "def f_skewness_raw(data):\n",
    "    ...\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis_raw(data):\n",
    "    ...\n",
    "    return kurtosis\n",
    "\n",
    "\n",
    "# Skewness\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "\n",
    "x_skewness_raw = f_skewness_raw(x)\n",
    "y_skewness_raw = f_skewness_raw(y)\n",
    "print(f'Raw skewness: {x_skewness},{y_skewness}')\n",
    "\n",
    "# Kurtosis\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "\n",
    "x_kurtosis_raw = f_kurtosis_raw(x)\n",
    "y_kurtosis_raw = f_kurtosis_raw(y)\n",
    "print(f'Raw kurtosis: {x_kurtosis_raw},{y_kurtosis_raw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cd8f9-11d4-415e-a53d-ad15737657c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fc926",
   "metadata": {},
   "source": [
    "<a name='section_3_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 3: Calorimetry and clustering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14556f-e6ee-4a4e-83f2-e15cfe644f85",
   "metadata": {},
   "source": [
    "Due to the complex patterns of particle interactions, EMCal readouts can become dense and chaotic.\n",
    "In these situations, clustering algorithms are essential to group hits that originate from a single particle, \n",
    "helping to reconstruct particle flows or analyze jets.\n",
    "\n",
    "The $K$-means algorithm is a popular unsupervised machine learning technique used to partition data into $K$ distinct clusters based on feature similarity. \n",
    "\n",
    "- $\\textbf{Initialize centroids}$: Randomly select $K$ hits; these hits will be the starting, $K$, centroids\n",
    "\n",
    "- $\\textbf{Assign clusters}$: Assign hits to the nearest centroid, forming $K$ clusters\n",
    "\n",
    "- $\\textbf{Update centroids and reassign hits}$: Calculate the centroid (mean of the coordinates) of each cluster; check if a hit in a cluster is closer to another centroid; if so, reallocate the hits to the closest cluster.\n",
    "\n",
    "- $\\textbf{Iterate}$: Repeat step 3 until no more hits change cluster (or until a certain tolerance).\n",
    "\n",
    "- $\\textbf{Output}$: The final centroids represent the centers of the $K$ clusters, and each hit is assigned to the cluster of its nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d80be",
   "metadata": {},
   "source": [
    "<a name='section_3_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.1: A homemade K-means clustering algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4614b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize the event 0 from the electron sample and the event 6 from the dielectron sample and then compute the relevant moments. Do they still provide a good description for multi-particle cases? Why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event 0, electron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "\n",
    "# Event 6, dielectron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bef23b-c2c3-4b75-a660-79401dbe96aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03da784",
   "metadata": {},
   "source": [
    "For cases with particle gun decays, we can perform clustering to group the hits associated with different secondary particles produced in the decay.\n",
    "\n",
    "To test the clustering algorithms and evaluate if they are implemented correctly, you can use the following method to randomly generate a number of clusters with a given number of hits.\n",
    "\n",
    "```\n",
    "import ex3\n",
    "points = ex3.generate_2d_points()\n",
    "# ex3.generate_2d_points(num_clusters=X, points_per_cluster=Y, spread=Z, random_seed=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721df28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Generate some points with the default settings (without passing arguments) and also with some custom settings and visualize the generated datasets.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_points(num_clusters, points_per_cluster, spread, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    data = []\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        center = np.random.uniform([-120, -60], [120, 60])\n",
    "        cluster_points = center + np.random.randn(points_per_cluster, 2) * spread\n",
    "        data.append(cluster_points)\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_constant_array(array, constant=1):\n",
    "    return np.full(array.shape[0], constant)\n",
    "\n",
    "\n",
    "i=0\n",
    "for n in [2, 4, 6]:\n",
    "    for p in [10, 20, 30]:\n",
    "        for s in [1., 3., 5.]:\n",
    "            i+=1\n",
    "            coordinates = generate_2d_points(num_clusters=n, points_per_cluster=p, spread=s, random_seed=i)\n",
    "            energies = get_constant_array(array=coordinates, constant=1)\n",
    "            plot_spatial_energy_matrix(coordinates=coordinates, energies=energies, title=f'Clusters: {n}, Points per clusters: {p}, Spread: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b267cd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>üß© Exercise: K-Means Clustering</h3>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>What is Cluster Analysis?</h4>\n",
    "\n",
    "<p>\n",
    "Cluster analysis is the process of <strong>grouping together similar points into clusters</strong>.\n",
    "A <em>point</em> can have 2, 3, or even hundreds of dimensions ‚Äî meaning it‚Äôs a vector in some space.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "One practical example is <strong>epidemiological clustering</strong>:\n",
    "you might have 2D points representing the <strong>longitude and latitude</strong> of locations where birds carrying different strains of avian flu were found.\n",
    "By clustering these points, you can gain insight into which regions correspond to each strain.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Distances Between Points</h4>\n",
    "\n",
    "<p>\n",
    "To cluster data, we must measure <strong>how close or far</strong> points are from each other.\n",
    "The <strong>Euclidean distance</strong> is the most common measure.\n",
    "</p>\n",
    "\n",
    "<p>For two 2D points:</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2}\n",
    "\\]\n",
    "\n",
    "<p>For two 3D points:</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2 + (p_z - q_z)^2}\n",
    "\\]\n",
    "\n",
    "<p>In general, for two \\(n\\)-dimensional points\n",
    "\\(p = (p_1, p_2, \\dots, p_n)\\) and \\(q = (q_1, q_2, \\dots, q_n)\\):</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2}\n",
    "\\]\n",
    "\n",
    "<p><strong>Example:</strong></p>\n",
    "\\[\n",
    "p = (0.1, 0.2, 0.3, 0.4), \\quad q = (0.0, 0.2, 0.3, 0.2)\n",
    "\\]\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(0.1-0.0)^2 + (0.2-0.2)^2 + (0.3-0.3)^2 + (0.4-0.2)^2} = 0.7071\\ldots\n",
    "\\]\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Cluster Centroids</h4>\n",
    "\n",
    "<p>\n",
    "The <strong>centroid</strong> of a cluster is its <em>center of mass</em> ‚Äî the <strong>average position</strong> of all points in that cluster.\n",
    "Even though it‚Äôs the mean of all cluster points, the centroid does <em>not</em> need to be one of those points.\n",
    "</p>\n",
    "\n",
    "<p>To compute a centroid:</p>\n",
    "\\[\n",
    "\\text{centroid} = \\frac{1}{N} \\sum_{i=1}^{N} p_i\n",
    "\\]\n",
    "\n",
    "<p>Vector operations:</p>\n",
    "\\[\n",
    "p + q = (p_1 + q_1,\\, p_2 + q_2,\\, \\dots,\\, p_n + q_n)\n",
    "\\]\n",
    "\\[\n",
    "\\frac{p}{a} = \\left(\\frac{p_1}{a},\\, \\frac{p_2}{a},\\, \\dots,\\, \\frac{p_n}{a}\\right)\n",
    "\\]\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>The K-Means Algorithm</h4>\n",
    "\n",
    "<p>\n",
    "The <strong>idea</strong> behind K-Means is simple:\n",
    "each point belongs to the cluster whose centroid (mean) it is <strong>closest</strong> to.\n",
    "Because centroids depend on which points are assigned to them, and assignments depend on centroids, we solve this <em>chicken-and-egg</em> problem iteratively.\n",
    "</p>\n",
    "\n",
    "<h5>Step 1. Pick \\(k\\) Centroids</h5>\n",
    "\n",
    "<p>\n",
    "We start by choosing \\(k\\), the number of clusters we want.\n",
    "Each centroid \\(m_j\\) is an \\(n\\)-dimensional point:\n",
    "</p>\n",
    "\\[\n",
    "m_j = (m_{j,1}, m_{j,2}, \\dots, m_{j,n})\n",
    "\\]\n",
    "<p>\n",
    "We randomly select \\(k\\) points from the dataset as our <strong>initial centroids</strong>\n",
    "(the <em>Forgy method</em>).\n",
    "</p>\n",
    "\n",
    "<h5>Step 2. Partition the Dataset</h5>\n",
    "\n",
    "<p>\n",
    "Assign each point to the <strong>nearest centroid</strong> by Euclidean distance.\n",
    "If a point is equally close to multiple centroids, break ties arbitrarily.\n",
    "This produces \\(k\\) sets \\(S_1, S_2, \\dots, S_k\\),\n",
    "where each \\(S_j\\) contains all points closest to centroid \\(m_j\\).\n",
    "</p>\n",
    "\n",
    "<h5>Step 3. Recompute the Means</h5>\n",
    "\n",
    "<p>For each cluster \\(S_j\\), recompute its centroid:</p>\n",
    "\\[\n",
    "m_j = \\frac{1}{|S_j|} \\sum_{q \\in S_j} q\n",
    "\\]\n",
    "<p>\n",
    "Since centroids have changed, some points may now be closer to a different centroid ‚Äî\n",
    "so we repeat the assignment step.\n",
    "</p>\n",
    "\n",
    "<h5>Step 4. Repeat Until Convergence</h5>\n",
    "\n",
    "<ul>\n",
    "  <li>The centroids stop moving, or</li>\n",
    "  <li>The assignments no longer change.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Sometimes convergence takes many iterations, so we often set a\n",
    "<strong>maximum iteration limit</strong> to prevent infinite loops.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Summary of the K-Means Algorithm</h4>\n",
    "\n",
    "<ol>\n",
    "  <li>Choose \\(k\\) and initialize centroids randomly.</li>\n",
    "  <li>Assign each point to the nearest centroid.</li>\n",
    "  <li>Recompute each centroid as the mean of its assigned points.</li>\n",
    "  <li>Repeat steps 2‚Äì3 until centroids stop changing or max iterations reached.</li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>‚úÖ Key Idea:</strong>  \n",
    "K-Means minimizes the <em>within-cluster sum of squared errors</em> (inertia) ‚Äî  \n",
    "the total squared distance between points and their assigned centroids.</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad69ab-3530-4b45-9461-29d712c19312",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Fill the missing parts in the following class to implement the k-means algorithm.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Minimal NumPy-only implementation of the K-Means clustering algorithm.\n",
    "\n",
    "    This class groups data points into `n_clusters` clusters by repeatedly\n",
    "    performing two steps:\n",
    "      1. Assign each point to the nearest cluster center (centroid).\n",
    "      2. Recompute each centroid as the mean of the points assigned to it.\n",
    "\n",
    "    The process stops when either:\n",
    "      - The centroids stop moving (i.e., total movement < `tol`), or\n",
    "      - The maximum number of iterations (`max_iter`) is reached.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "        Number of clusters (K). Must be >= 1.\n",
    "    init : {\"k-means++\", \"random\"}\n",
    "        Initialization scheme for the centroids.\n",
    "        - \"random\": pick K random points from the data as initial centroids.\n",
    "        - \"k-means++\": smarter initialization that spreads out initial centroids.\n",
    "    max_iter : int\n",
    "        Maximum number of K-Means iterations (assign + update steps).\n",
    "    tol : float\n",
    "        Convergence tolerance on centroid shift (Euclidean norm).\n",
    "        If the total movement of all centroids is less than this value,\n",
    "        the algorithm stops early.\n",
    "    random_state : int or None\n",
    "        Seed for random number generators (both Python's `random` and NumPy's).\n",
    "        Use this for reproducible results.\n",
    "\n",
    "    Attributes (set after calling fit)\n",
    "    ----------------------------------\n",
    "    cluster_centers_ : ndarray of shape (n_clusters, n_features)\n",
    "        Final positions of the cluster centroids.\n",
    "    labels_ : ndarray of shape (n_samples,)\n",
    "        Cluster index (0 to n_clusters-1) assigned to each sample in X.\n",
    "    inertia_ : float\n",
    "        Final value of the K-Means objective:\n",
    "        sum of squared distances of each point to its assigned centroid.\n",
    "    n_iter_ : int\n",
    "        Number of iterations run until convergence (or reaching max_iter).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=None):\n",
    "        self.n_clusters   = int(n_clusters)\n",
    "        self.init         = init\n",
    "        self.max_iter     = int(max_iter)\n",
    "        self.tol          = float(tol)\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Attributes set after fitting\n",
    "        self.cluster_centers_ = None  # centroids after fitting\n",
    "        self.labels_          = None  # cluster labels for each sample\n",
    "        self.inertia_         = None  # final within-cluster sum of squares\n",
    "        self.n_iter_          = None  # number of iterations performed\n",
    "\n",
    "    # ---------- core primitives ----------\n",
    "\n",
    "    def _euclidean_squared(self, a, b):\n",
    "        \"\"\"\n",
    "        Compute squared Euclidean distances between two sets of vectors.\n",
    "\n",
    "        This is a vectorized computation of:\n",
    "            dist^2(a[i], b[j]) = ||a[i] - b[j]||^2\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        a : ndarray of shape (n_samples, n_features)\n",
    "            First set of vectors (e.g., data points).\n",
    "        b : ndarray of shape (n_centroids, n_features)\n",
    "            Second set of vectors (e.g., centroids).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        d2 : ndarray of shape (n_samples, n_centroids)\n",
    "            d2[i, j] is the squared distance between a[i] and b[j].\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        We avoid explicit Python loops by using the identity:\n",
    "            ||x - y||^2 = ||x||^2 - 2 x¬∑y + ||y||^2\n",
    "        computed in a fully vectorized way.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return a2 - 2.0 * ab + b2\n",
    "\n",
    "    def _kmeanspp_init(self, X, rng):\n",
    "        \"\"\"\n",
    "        Initialize centroids using the k-means++ algorithm.\n",
    "\n",
    "        The idea:\n",
    "          1. Choose one initial centroid uniformly at random from X.\n",
    "          2. For each remaining centroid:\n",
    "             - Compute the distance of each point to its closest chosen centroid.\n",
    "             - Choose the next centroid at random, with probability proportional\n",
    "               to distance^2 (points far away from existing centroids are more\n",
    "               likely to be chosen).\n",
    "\n",
    "        This tends to produce better (more spread out) initial centroids than\n",
    "        simple random selection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        rng : np.random.Generator\n",
    "            NumPy random number generator (already seeded).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Initial centroid positions.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    # ---------- step-by-step methods ----------\n",
    "\n",
    "    def _initialize_centroids(self, X, rng=None):\n",
    "        \"\"\"\n",
    "        Step 2: Initialize centroids before starting the K-Means iterations.\n",
    "\n",
    "        For this implementation, we use simple random initialization:\n",
    "        we generate K distinct samples as the initial centroids.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        rng : np.random.Generator or None\n",
    "            Unused here (kept for API symmetry with other methods).\n",
    "            Python's built-in `random` module is used instead.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Initial centroid positions generated randomly within the range of given sample points.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - If `random_state` is provided in the constructor, we seed the Python\n",
    "          `random` module to make the choice of initial points reproducible.\n",
    "        - This method currently ignores the `init` parameter and always uses\n",
    "          random initialization. A more advanced version could switch between\n",
    "          this and `_kmeanspp_init`.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return centroids\n",
    "\n",
    "    def _assign(self, X, centroids):\n",
    "        \"\"\"\n",
    "        Step 3: Assignment step ‚Äî assign each point to the nearest centroid.\n",
    "\n",
    "        For each sample x_i in X, we find the centroid c_j that minimizes\n",
    "        the squared Euclidean distance ||x_i - c_j||^2, and assign x_i\n",
    "        to cluster j.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Current centroid positions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            labels[i] is the index (0..K-1) of the closest centroid to X[i].\n",
    "        d2 : ndarray of shape (n_samples, n_clusters)\n",
    "            Squared distances from each point to each centroid.\n",
    "            d2[i, j] = ||X[i] - centroids[j]||^2.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The actual assignment only uses the argmin of distances, but we also\n",
    "        return the full distance matrix `d2` as it can be useful for analysis.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return labels, d2\n",
    "\n",
    "    def _update(self, X, labels, rng):\n",
    "        \"\"\"\n",
    "        Step 4: Update step ‚Äî recompute centroids from current assignments.\n",
    "\n",
    "        For each cluster j, we:\n",
    "          - Collect all points assigned to cluster j.\n",
    "          - Compute their mean along each feature dimension.\n",
    "          - Use this mean vector as the new centroid for cluster j.\n",
    "\n",
    "        If a cluster becomes \"empty\" (i.e., no points are assigned to it),\n",
    "        we handle it by re-seeding that centroid to a random point.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index for each sample.\n",
    "        rng : np.random.Generator\n",
    "            NumPy random number generator (already seeded), used to\n",
    "            handle empty clusters by choosing a random point.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        new_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Updated centroid positions after recomputing means.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Empty cluster handling is important: K-Means sometimes creates\n",
    "        clusters that end up with no assigned points. Without re-seeding,\n",
    "        we would get NaNs or invalid centroids.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "       \n",
    "        return new_centroids\n",
    "\n",
    "    def _converged(self, old_centroids, new_centroids, old_labels, new_labels):\n",
    "        \"\"\"\n",
    "        Step 5: Convergence check ‚Äî decide whether to stop iterating.\n",
    "\n",
    "        We consider two possible convergence criteria:\n",
    "\n",
    "          1. Label stability:\n",
    "             If cluster assignments (labels) do not change between two\n",
    "             consecutive iterations (`old_labels == new_labels`), the\n",
    "             algorithm has reached a stable clustering.\n",
    "\n",
    "          2. Centroid movement:\n",
    "             We compute the total movement of centroids as the Euclidean norm\n",
    "             of the difference between old and new centroids:\n",
    "                 shift = ||new_centroids - old_centroids||_F\n",
    "             (Frobenius norm). If `shift < tol`, we also stop.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        old_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Centroids from the previous iteration.\n",
    "        new_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Centroids from the current iteration.\n",
    "        old_labels : ndarray of shape (n_samples,) or None\n",
    "            Cluster labels from the previous iteration (None on first iteration).\n",
    "        new_labels : ndarray of shape (n_samples,)\n",
    "            Cluster labels from the current iteration.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        converged : bool\n",
    "            True if convergence criteria are met, False otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "        \n",
    "        return shift < self.tol\n",
    "\n",
    "    def _compute_inertia(self, X, labels, centroids):\n",
    "        \"\"\"\n",
    "        Step 6: Compute inertia (within-cluster sum of squared errors).\n",
    "\n",
    "        Inertia is the K-Means objective function:\n",
    "            inertia = sum_i ||X[i] - centroids[labels[i]]||^2\n",
    "\n",
    "        Lower inertia means that points are, on average, closer to their\n",
    "        assigned centroids (tighter clusters).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index for each sample.\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Final centroids.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        inertia : float\n",
    "            Sum of squared distances from points to their assigned centroids.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return inertia\n",
    "    # ---------- public API ----------\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Run K-Means clustering on the dataset X.\n",
    "\n",
    "        This method performs the full algorithm:\n",
    "          1. Initialize centroids.\n",
    "          2. Repeat until convergence or reaching max_iter:\n",
    "             a. Assign each point to the nearest centroid.\n",
    "             b. Update centroids as means of assigned points.\n",
    "             c. Check for convergence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input data to be clustered. Will be converted to a NumPy array\n",
    "            of dtype float.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : KMeans\n",
    "            The fitted instance (for method chaining).\n",
    "\n",
    "        Side effects\n",
    "        ------------\n",
    "        After calling fit, the following attributes are set:\n",
    "          - self.cluster_centers_\n",
    "          - self.labels_\n",
    "          - self.inertia_\n",
    "          - self.n_iter_\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Assign cluster labels to new data points using fitted centroids.\n",
    "\n",
    "        This does **not** run the K-Means algorithm again; it simply\n",
    "        assigns each new point to the nearest existing centroid from\n",
    "        `self.cluster_centers_`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            New data points to assign to clusters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index (0..K-1) for each row of X.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If the model has not been fitted yet (i.e. `fit` has not been called).\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Convenience method: fit the model on X and return cluster labels.\n",
    "\n",
    "        This is equivalent to:\n",
    "            kmeans.fit(X)\n",
    "            labels = kmeans.labels_\n",
    "\n",
    "        but implemented as a single method for convenience.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input data to cluster.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index assigned to each sample in X.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df5cd0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 1:</strong> \n",
    "use the cell below to evalue inertia and iterations K-Means you have implemented</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ---- Load Iris dataset ----\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "# ---- Your implementation ----\n",
    "my_km = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=34)\n",
    "my_labels = my_km.fit_predict(X)\n",
    "\n",
    "print(\"=== Your KMeans ===\")\n",
    "print(f\"Iterations: {my_km.n_iter_}\")\n",
    "print(f\"Inertia: {my_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, my_labels):.4f}\")\n",
    "\n",
    "# ---- scikit-learn implementation ----\n",
    "sk_km = SKKMeans(n_clusters=3, init=\"k-means++\", n_init=1, max_iter=300, tol=1e-4,\n",
    "                 algorithm=\"lloyd\", random_state=42)\n",
    "sk_labels = sk_km.fit_predict(X)\n",
    "\n",
    "print(\"\\n=== scikit-learn KMeans ===\")\n",
    "print(f\"Iterations: {sk_km.n_iter_}\")\n",
    "print(f\"Inertia: {sk_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, sk_labels):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8f83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 2:</strong> \n",
    "Import the external unit test, check if home-brewed K-Means has passed all the test</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i unit_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37abc2d",
   "metadata": {},
   "source": [
    "<a name='section_3_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.2: Finding optimal number of centroids</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095a4e6-5ecd-4af4-bbbe-8ae7b238fe18",
   "metadata": {},
   "source": [
    "$K$-means is an efficient method that works well with large datasets, making it ideal for quickly organizing data into clusters based on similarity.\n",
    "However, one limitation is that the number of clusters, $K$, must be predetermined, which can be challenging without prior knowledge of the data structure.\n",
    "To address this, techniques such as the Elbow and the Silhouette methods are often used to find the optimal number of clusters, helping to ensure that the chosen $K$ best captures the natural groupings within the data.\n",
    "In any case, for a given event, one must run the $K$-means algorithm multiple times, scanning different values of $K$ and identifying the optimal value of $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e124a-3f31-442d-a76e-8a460b47a7f3",
   "metadata": {},
   "source": [
    "$\\textbf{Elbow method}$\n",
    "\n",
    "The Elbow Method helps find the optimal number of clusters \\( K \\) by computing the within-cluster sum of squares (WCSS$_K$):\n",
    "$$\n",
    "    \\text{WCSS}_K = \\sum_{i=1}^{K} \\sum_{x \\in C_i} \\| x - \\mu_i \\|^2\n",
    "$$\n",
    "where $K$ is the number of clusters, $C_i$ is the $i$-th cluster, $x$ is a hit in the cluster, $\\mu_i$ is the centroid of the cluster $C_i$, and $\\| x - \\mu_i \\|^2$ is the squared Euclidean distance between the hit and the centroid.\n",
    "If you plot WCSS$_K$ as a function of $K$, you will notice that as \\( K \\) increases, WCSS$_K$ decreases.\n",
    "The \"elbow\" point, where the decrease slows down \"sharply\", indicates the optimal \\( K \\).\n",
    "\n",
    "To determine the elbow point more precisely, you can:\n",
    "calculate the second derivative of WCSS with respect to \\( K \\) and identify the point with the largest change, indicating the most significant slowdown in the rate of decrease;\n",
    "use algorithms such as the \"Kneedle\" algorithm, which automatically detects the \"knee\" or \"elbow\" in the curve by analyzing the curvature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f193263-1f6a-4ccd-8ea5-f669e6a9b68d",
   "metadata": {},
   "source": [
    "$\\textbf{Silouette method}$\n",
    "\n",
    "The Silhouette method evaluates the quality of clustering by calculating a \"silhouette score\" for each hit, based on how similar it is to hits in its own cluster compared to hits in the nearest other cluster. For a given number of clusters \\( K \\), the average silhouette score $S$ ranges from -1 to 1: $S$ near 1 indicates well-clustered hits, close to their own cluster and far from others; $S$ near 0 indicates the presence of hits on the boundary between clusters (overlapping clusters); a negative $S$ indicates that many hits are assigned to the wrong cluster.\n",
    "\n",
    "To determine the optimal \\( K \\), calculate the average silhouette score for different \\( K \\) values and choose the \\( K \\) that maximizes this score, indicating the best-defined clusters.\n",
    "Here is a method to calculate the silhouette score $S$:\n",
    "\n",
    "- Compute the intra-cluster distance $a_i$: for each hit $i$ in a cluster, compute the average Euclidean distance to all other points within the same cluster.\n",
    "- Compute the nearest cluster distance $b_i$: for each hit $i$ in a cluster, compute the average euclidean distance to all points of another cluster; repeat for all clusters and take the smallest average distance computed.\n",
    "- Compute silhouette hit score $s_i$: for each hit $i$ in a cluster, compute\n",
    "    $$\n",
    "    s_i = \\frac{b_i - a_i}{\\max(a_i, b_i)}\n",
    "    $$\n",
    "    and repeat it for all hits in the event.\n",
    "- Calculate the average silhouette score $S$ of the event, i.e. the average of $s_i$ over all hits in the event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9947f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Implement an elbow method for your K-means algorithm and test it on a few events to evaluate its performance. </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a268a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(data, score_method, title_label, min_k=1, max_k=10):\n",
    "    \"\"\"\n",
    "    Evaluate a clustering quality score for different numbers of clusters K\n",
    "    and visualize both:\n",
    "      1) The clustering in 2D for each K.\n",
    "      2) How the score changes as a function of K (Elbow-style plot).\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1. Loop over K from min_k to max_k.\n",
    "    2. For each K:\n",
    "       - Run k-means to get centroids and labels.\n",
    "       - Compute a clustering score using `score_method`.\n",
    "       - Plot the clustered data in 2D with colors for each cluster and\n",
    "         centroids drawn on top.\n",
    "       - Store the score in a list.\n",
    "    3. After the loop, plot \"score vs K\" to help choose the optimal K.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        Input data points to be clustered.\n",
    "    score_method : callable\n",
    "        Function that takes (data, centroids, labels) and returns a numeric\n",
    "        score (e.g., WCSS). Lower or higher is \"better\" depending on the\n",
    "        method.\n",
    "    title_label : str\n",
    "        Label used in plot titles (e.g. \"Elbow method\").\n",
    "    min_k : int, default=1\n",
    "        Minimum number of clusters to evaluate.\n",
    "    max_k : int, default=10\n",
    "        Maximum number of clusters to evaluate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score_values : list of float\n",
    "        List of scores, where score_values[i] corresponds to\n",
    "        K = min_k + i.\n",
    "    \"\"\"\n",
    "    score_values = []\n",
    "\n",
    "    # After evaluating all K, plot score as a function of K (Elbow plot)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(range(min_k, max_k + 1), score_values, marker='o', linestyle='--')\n",
    "    plt.title(f\"{title_label} method for the optimal K\")\n",
    "    plt.xlabel(\"Number of clusters (K)\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.show()\n",
    "\n",
    "    return score_values\n",
    "\n",
    "\n",
    "def wcss_score(data, centroids, labels):\n",
    "    \"\"\"\n",
    "    Compute WCSS (Within-Cluster Sum of Squares) for a given clustering.\n",
    "\n",
    "    WCSS is defined as:\n",
    "        sum over all clusters i of\n",
    "            sum over all points x in cluster i of\n",
    "                ||x - centroid_i||^2\n",
    "\n",
    "    Intuitively:\n",
    "      - For each cluster, we measure how far its points are from the cluster\n",
    "        centroid (squared distance).\n",
    "      - We sum all these squared distances.\n",
    "      - Lower WCSS means more compact, tighter clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        Input data points.\n",
    "    centroids : ndarray of shape (k, n_features)\n",
    "        Centroid coordinates for each cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        labels[j] is the index (0..k-1) of the cluster assigned to data[j].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wcss : float\n",
    "        Total within-cluster sum of squared distances.\n",
    "    \"\"\"\n",
    "    wcss = 0.0\n",
    "\n",
    "    # implement this function\n",
    "    \n",
    "    return wcss\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Example usage: generate synthetic data with different true numbers\n",
    "# of clusters and run the \"Elbow method\" evaluation.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "for n in [2, 4, 6]:\n",
    "    print('###############################################################################################')\n",
    "    print(f'Generating {n} clusters...')\n",
    "\n",
    "    # Generate a 2D dataset with `n` well-separated clusters\n",
    "    coordinates = generate_2d_points(\n",
    "        num_clusters=n,\n",
    "        points_per_cluster=20,\n",
    "        spread=4.0,\n",
    "        random_seed=999\n",
    "    )\n",
    "\n",
    "    # Evaluate WCSS for K = 2..10 and visualize clusters + elbow plot\n",
    "    evaluate_method(\n",
    "        data=coordinates,\n",
    "        score_method=wcss_score,\n",
    "        title_label='Elbow method',\n",
    "        min_k=2,\n",
    "        max_k=10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d95e60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Implement a silhouette method for your K-means algorithm and test it on few events to evaluate its performance.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(data, centroids, labels):\n",
    "    \"\"\"\n",
    "    Compute the Silhouette Score for a given clustering.\n",
    "\n",
    "    The silhouette score measures how well each point fits within its cluster\n",
    "    compared to other clusters. It ranges from:\n",
    "        -1  ‚Üí very poor clustering (point is closer to another cluster)\n",
    "         0  ‚Üí ambiguous / overlapping clusters\n",
    "         1  ‚Üí very good clustering (point well inside its own cluster)\n",
    "\n",
    "    For each point i:\n",
    "        a_i = average distance to other points in its own cluster\n",
    "        b_i = lowest average distance to points in any *other* cluster\n",
    "        s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "\n",
    "    The overall silhouette score is the average over all s_i.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The dataset being clustered.\n",
    "    centroids : ndarray of shape (k, n_features)\n",
    "        Centroid positions for the k clusters. (Not directly used here.)\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        labels[i] = index of the cluster assigned to data[i].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average silhouette score for the entire clustering.\n",
    "        Higher is better (best value is +1).\n",
    "    \"\"\"\n",
    "\n",
    "    total_score = 0\n",
    "    n_samples = data.shape[0]\n",
    "    k = len(centroids)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        point = data[i]\n",
    "        point_label = labels[i]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 1: Compute a_i = average intra-cluster distance\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 2: Compute b_i = closest *other* cluster\n",
    "        # For each other cluster j, compute the average distance to j.\n",
    "        # ------------------------------------------------------------\n",
    "       \n",
    "        # ------------------------------------------------------------\n",
    "        # Step 3: Compute silhouette value for this point\n",
    "        # s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        # ------------------------------------------------------------\n",
    "        \n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Final Step: Return average silhouette score over all points\n",
    "    # ------------------------------------------------------------\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02eb580",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Compare computational complexity for elbow and silhouette, and give your reasoning\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57425f-5eab-4751-99c2-04d012f09012",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807821c2-7c12-48fa-a751-632573909132",
   "metadata": {},
   "source": [
    "<h4> On the Computational Complexity of <em>Elbow</em> vs <em>Silhouette</em> Methods</h4>\n",
    "\n",
    "<p>Let:</p>\n",
    "\n",
    "<ul>\n",
    "  <li>\\( n \\) ‚Äî number of points</li>\n",
    "  <li>\\( d \\) ‚Äî dimensionality</li>\n",
    "  <li>\\( k \\) ‚Äî clusters</li>\n",
    "  <li>\\( I \\) ‚Äî K-Means iterations until convergence</li>\n",
    "  <li>\\( K_{\\max} \\) ‚Äî maximum number of clusters you scan in your model selection loop</li>\n",
    "</ul>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h5>A) Elbow Method (WCSS / Inertia)</h5>\n",
    "\n",
    "<ol>\n",
    "  <li>Run K-Means once per \\(k\\):  \n",
    "      Cost \\( \\approx \\mathcal{O}(n \\cdot k \\cdot I \\cdot d) \\) (standard Lloyd‚Äôs algorithm).</li>\n",
    "  <li>Compute WCSS / inertia: obtained during the same pass; extra \\( \\mathcal{O}(n \\cdot d) \\).</li>\n",
    "</ol>\n",
    "\n",
    "<p>\n",
    "Per \\(k\\):  \n",
    "\\[\n",
    "\\boxed{\\mathcal{O}(n \\cdot k \\cdot I \\cdot d)}\n",
    "\\]\n",
    "Scan \\(k = 2..K_{\\max}\\):  \n",
    "\\[\n",
    "\\boxed{\\mathcal{O}(K_{\\max} \\cdot n \\cdot k \\cdot I \\cdot d)}\n",
    "\\]\n",
    "Memory: \\( \\mathcal{O}(n \\cdot d) \\)\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h5>B) Silhouette Method</h5>\n",
    "\n",
    "<p>\n",
    "You still need to run K-Means per \\(k\\):  \n",
    "\\( \\mathcal{O}(n \\cdot k \\cdot I \\cdot d) \\)\n",
    "</p>\n",
    "\n",
    "<p>Then compute silhouette:</p>\n",
    "\n",
    "<ul>\n",
    "  <li><strong>Na√Øve per-point:</strong> for each point, distances to all others  \n",
    "      \\( \\Rightarrow \\mathcal{O}(n^2 \\cdot d) \\)</li>\n",
    "  <li><strong>Precompute distance matrix (per \\(k\\)):</strong>  \n",
    "      \\( \\mathcal{O}(n^2 \\cdot d) \\) time and \\( \\mathcal{O}(n^2) \\) memory,  \n",
    "      then reuse to get \\(a_i, b_i\\) in \\( \\mathcal{O}(n) \\).</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Per \\(k\\) (na√Øve or precomputed):  \n",
    "\\[\n",
    "\\boxed{\\mathcal{O}(n \\cdot k \\cdot I \\cdot d) \\;+\\; \\mathcal{O}(n^2 \\cdot d)}\n",
    "\\]\n",
    "Scan \\(k = 2..K_{\\max}\\):  \n",
    "\\[\n",
    "\\boxed{\\mathcal{O}\\!\\left(K_{\\max} \\cdot n \\cdot k \\cdot I \\cdot d \\;+\\; K_{\\max} \\cdot n^2 \\cdot d\\right)}\n",
    "\\]\n",
    "Memory (with precompute): \\( \\mathcal{O}(n^2) \\)\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed6acb-9e33-42bd-b377-4f49b236d530",
   "metadata": {},
   "source": [
    "$\\textbf{Energy seeding}$\n",
    "\n",
    "Now let's change our approach in the determination of \\(K\\) from the perspective of physics.\n",
    "The EMCal readouts provide not only the hit position information, but also the energy deposition measured for each hit.\n",
    "On top of that, we know that a particle typically deposits large part of its energy in one channel, with only small fractions leaking to the neighboring channels due to the lateral spread of the shower. We can exploit this knowledge to design an algorithm tailored to our physics case.\n",
    "\n",
    "\"Energy seeds\" in calorimetry refer to localized points in the detector where the energy deposition is significantly higher than the surrounding areas. These seeds act as initial markers for clustering algorithms, helping to identify and group hits that are likely to belong to the same cluster. By starting with these high-energy regions, energy seed-based clustering improves accuracy in reconstructing particle trajectories and separating overlapping showers.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/padding.png\" width=\"40%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Illustration of a possible logic for seed search. </figcaption>\n",
    "</div>\n",
    "\n",
    "Here there is an idea for a seed-searching algorithm:\n",
    "- Suppose we have a $15 \\times 15$ EMCal grid and create a $(15+1) \\times (15+1)$ 2D array initialized with zeros.\n",
    "- Assign energy values to the cells based on their $\\texttt{elmID}$.\n",
    "- Apply a minimum energy mask to identify potential energy seed candidates (i.e., we consider as a seed only an energy deposit above a certain threshold).\n",
    "- Sort the energy seeds in ascending order.\n",
    "- Add a padding region for each seed candidate. If any hit within the padding region has a higher energy than the candidate, discard the candidate.\n",
    "  \n",
    "Loop through the list of energy seed candidates.\n",
    "\n",
    "The seed candidates you find can then be used as a starting point for the $K$-means clustering algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e463ec0-6273-4b05-8413-236e17f70e8c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Implement a seed-searching algorithm for your K-means algorithm and test it on few events to evaluate its performance. Note that, for this case, you need to use the events from the dielectron sample.\n",
    "\n",
    "What parameters of the algorithm you can tune to improve its performance?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9900bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to implement the seed_search function\n",
    "\n",
    "def seed_search(channels, energies, min_energy_threshold=5.0, padding_size=1, n_rows=72, n_columns=36):\n",
    "    # Step 1: Map energies to the 2D energy matrix\n",
    "\n",
    "    # Step 2: Apply minimum energy threshold to identify potential seed candidates\n",
    "    # Creating a binary mask where energy values are greater than the threshold\n",
    "\n",
    "    # Step 3: Get the coordinates of the potential seeds\n",
    "\n",
    "    # Step 4: Sort seeds by their energy values (ascending)\n",
    "\n",
    "    # Step 5: Define a padding region and check for neighboring cells with higher energy\n",
    "        # Extract the neighboring region (within bounds)\n",
    "        # If any neighboring cell has energy greater than the current seed, discard it\n",
    "\n",
    "        # Otherwise, keep this seed\n",
    "\n",
    "    return valid_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8edbf29-9de9-4b01-a583-580a9ba2a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the algorithm on a few events from the dielectron sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed0445-9f0c-47fa-95dc-095115edc830",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
