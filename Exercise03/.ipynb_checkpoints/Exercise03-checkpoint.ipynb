{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1c50278",
   "metadata": {},
   "source": [
    "# √úbungen zu Teilchenphysik I\n",
    "## Exercise 03 - EMCal in a nutshell\n",
    "\n",
    "    D. Wong, November 2025                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82039ad",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "It is very likely that you will need the following packages, so don't forget to import them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "# This is a local module that will be necessary for the sections 2 and 3: it's already provided in this repository\n",
    "import exercise3_utils as ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad70f3aa-e25b-4929-b97b-b33325e649d8",
   "metadata": {},
   "source": [
    "<a name='section_1_0'></a>\n",
    "\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 1: Electromagnetic cascades in a calorimeter</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb08dab",
   "metadata": {},
   "source": [
    "An **electromagnetic (EM) shower** is a cascade of particles, including photons, electrons, and positrons, forms when a high-energy electron or photon interacts with dense material and produces a chain of secondary particles. Photons convert into electron‚Äìpositron pairs, and these charged particles in turn emit bremsstrahlung photons, repeating the process as the shower multiplies and spreads. The cascade continues until particle energies fall below a critical value, where ionization dominates and the shower dies out. In an electromagnetic calorimeter (EMCal), this process is harnessed to measure particle energies: alternating layers of absorber and active material contain and sample the shower, converting the deposited energy into measurable signals. The total signal provides a precise estimate of the incident electron or photon‚Äôs energy and impact position, making EM calorimetry a key technique in modern high-energy physics experiments.\n",
    "\n",
    "<!--\n",
    "![EMShower](https://www.aanda.org/articles/aa/full/2003/43/aaINTEGRAL41/img17.gif)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4314fc-7782-45d0-b4d5-ffcd3ebe7988",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/x0.png\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Development of an electromagnetic shower </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b0a4b-ffff-40d7-a8d4-94211a460f9f",
   "metadata": {},
   "source": [
    "Bremsstrahlung is the primary energy loss process for electrons/positrons above ( $\\sim$ 10 )~MeV, while photons lose energy mainly through the production of electron‚Äìpositron pairs.\n",
    "High-energy photons, electrons, and positrons create a cascade of secondary particles‚Äîknown as an ‚Äúelectromagnetic shower.‚Äù\n",
    "\n",
    "The following quantities ($\\textit{Thomson‚Äôs approximation}$) are defined:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c5543-e1ef-446f-b612-debf15ea52c7",
   "metadata": {},
   "source": [
    "- $\\textbf{Radiation Length} ~X_0$: Average distance over which the electron energy reduces by 1/e:\n",
    "    \n",
    "    $$ X_0 \\approx \\frac{1}{4 \\, \\alpha \\, n \\, Z^2 \\, r_e^2 \\ln \\left( \\frac{287}{\\sqrt{Z}} \\right)} $$\n",
    "  \n",
    "    where $\\alpha$ is the fine-structure constant, $n$ is the number density of the nucleus, $Z$ is the atomic number of the nucles, and $r_e$ is the classical electron radius.\n",
    "\n",
    "- $\\textbf{Critical Energy} ~E_c$: Energy at which ionization becomes the dominant energy loss:\n",
    "    \n",
    "    $$ E_c \\approx \\frac{800\\text{MeV}}{Z} $$\n",
    "  \n",
    "\n",
    "- $\\textbf{Moli√®re Radius} ~R_M$: Represents the lateral spread of an electromagnetic shower, mainly due to multiple scattering:\n",
    "    \n",
    "    $$ R_M = \\frac{21 \\, \\text{MeV}}{E_c}  X_0 \\, (\\text{g/cm}^2) $$\n",
    "    \n",
    "    Approximately 95% of the shower energy is contained within $2 R_M$ (transverse width).\n",
    "\n",
    "- $\\textbf{Maximum Particle Count Length} ~x_{\\text{max}}$: The shower reaches the maximum particle count after $x_{\\text{max}}$ radiation lengths, given by:\n",
    "    \n",
    "    $$ x_{\\text{max}} = \\frac{\\ln(E / E_c)}{\\ln 2} X_0 $$\n",
    "  \n",
    "    where $E$ is the initial energy, and $x_{\\text{max}}$ is also called longitudinal depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6153ac2-69f8-41e7-812e-88d965062745",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/e_eng_loss.png\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Electron energy loss as a function of the energy </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebb60f",
   "metadata": {},
   "source": [
    "<a name='section_1_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.1: EMCal dimension estimation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1176f",
   "metadata": {},
   "source": [
    "**Electromagnetic calorimeters (EMCal)** are designed to measure the energy of particles using high-Z materials to trap the shower. \n",
    "\n",
    "The electrons in the shower produce scintillation light, and the amount of light collected is proportional to the total energy of the incident particles. This makes EMCal ideal for precisely measuring the energy of electrons, positrons, and photons.\n",
    "\n",
    "The CMS detector at the LHC uses lead tungstate (PbWO$_4$) as the EMCal material.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Rosalinde-Pots/publication/364997605/figure/fig3/AS:11431281094130646@1667393809224/Schematic-overview-of-the-Electromagnetic-Calorimeter-ECAL-of-CMS-Modified-from-32.jpg\" \n",
    "alt=\"CMS ECAL\"\n",
    "width=\"600\" \n",
    "style= \"display:block; margin-left:auto; margin-right:auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130344ef-cfa8-4e81-aa38-d1b007a91da3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Calculate the radiation length and critical energy of Pb and PbWO$_4$. Then, compare your results with those available on the PDG website: <br>\n",
    "- Pb: <a href=\"https://pdg.lbl.gov/2024/AtomicNuclearProperties/HTML/lead_Pb.html\">link</a><br>\n",
    "- PbWO4: <a href=\"https://pdg.lbl.gov/2024/AtomicNuclearProperties/HTML/lead_tungstate.html\">link</a><br>\n",
    "<br>\n",
    "\n",
    "For PbWO$_4$, assume an effective atomic number Z = $\\dfrac{Z_{Pb} + Z_W + 4 \\times Z_O}{6}$ = $\\dfrac{82 + 74 + 4 \\times 8}{6}$ = 31.3 <br>\n",
    "and an effective atomic weigth A = $\\dfrac{A_{Pb} + A_W + 4 \\times A_O}{6}$ = $\\dfrac{207.2 + 183.8 + 4 \\times 16}{6}$ = 75.8 <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Do your calculated values correspond to what you found in the PDG page?\n",
    "\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2b96f-ae38-4d56-ae61-6379136af364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code. \n",
    "\n",
    "def critical_energy(..., ..., ...):\n",
    "    return ... # fill with formula\n",
    "\n",
    "def radiation_length(..., ..., ...):\n",
    "    return ... # fill with formula\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e9ad2b-9965-4d8f-a6f6-259cc5a16aa8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1e95a6",
   "metadata": {},
   "source": [
    "The effective atomic number and Thomson's approximation cannot produce a good estimation for the radiation length and the critical energy.\n",
    "\n",
    "Consult the PDG [website](https://pdg.lbl.gov/2024/AtomicNuclearProperties/) to get more precise values for both radiation length and critical energy for PbWO$_4$ (note that lead tungstate is an inorganic scintillator)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809505cb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Estimate the approximate dimension of an electromagnetic shower in a PbWO$_4$ crystal (longitudinal depth and transverse width) for a 100 GeV electron. \n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9667bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to estimate the shower depth and width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941f5ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Is this a good estimation for the size an EMCal should have? The CMS EMCal crystals are actually 25 $X_0$ long: why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ea7610-a6ca-4803-b015-834d5a437cf3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab1d98",
   "metadata": {},
   "source": [
    "<a name='section_1_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.2: Shape of muon clusters on EMCal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939b1749-9632-4d27-8866-85c0a8051fba",
   "metadata": {},
   "source": [
    "For muons with energies of the order of 100 GeV, the ionization is the dominant energy-loss process. <br>\n",
    "Muons travel significant distances in dense materials: for example, a 10 GeV muon loses about 10 MeV/cm in iron and has a range of several meters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7674bcce-123e-4a92-b060-cf61614b7e11",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/mu_eng_loss.png\" width=\"50%\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad892256-e723-4e4d-9723-ab91c0672ec3",
   "metadata": {},
   "source": [
    "A particle with a momentum close to the minimum ionization point is called a minimum ionizing particle (MIP). <br>\n",
    "A particle with a much larger momentum but with an energy loss comparable to that of the minimum ionization point is also called a MIP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5dd64c",
   "metadata": {},
   "source": [
    "For bremsstrahlung process, the energy loss through distance is given by: \n",
    "\n",
    "$-\\dfrac{dE}{dx} \\propto \\dfrac{Z^2 E}{m_{particle}^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68a4fdf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Consider a muon with a momentum of 50 GeV passing through the CMS EMCal, which has a depth of approximately 22 cm. What is the shape of the shower you expect? How do you expect the energy deposit to be distributed?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02f843-d4b2-4f88-8dfc-55827049b330",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc1c2ae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Knowing at what energy electrons and positrons start emitting significant bremsstrahlung (how is this transition energy called?), determine the threshold energy for a muon to emit significant bremsstrahlung in a PbWO$_4$ EMCal. \n",
    "In other words, what energy must a muon possess to deposit an amount of evenrgy equal to the critical energy?\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6bb5c-d72d-40ec-be76-180038464236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code \n",
    "\n",
    "# The energy at which electrons and positrons start emitting significant energy via bremsstrahlung is the critical energy.\n",
    "# Let's consider PbWO4: we already got from PDG that the critical energy for an electron is 9.64 MeV in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0066a",
   "metadata": {},
   "source": [
    "<a name='section_1_3'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 1.3: Detector proposal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb46def",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "How would you implement an experimental apparatus involving an EMCal so that it can distinguish electrons from photons and muons?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b79226-6388-4b7e-bf56-913d7dfe8b3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce470a2",
   "metadata": {},
   "source": [
    "<a name='section_2_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 2: Calorimetry and reconstruction</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b8b7a",
   "metadata": {},
   "source": [
    "In this section, we will consider a real EMCal, used in the [PHENIX](https://www.phenix.bnl.gov/) experiment at Brookhaven National Laboratory.\n",
    "\n",
    "We have prepared ROOT n-tuples containing hit information from the EMCal, using a particle gun with a gaussian energy distribution, ranging from 5 GeV to 80 GeV.\n",
    "\n",
    "The EMCal at the PHENIX experiment covers an area of $2~m~\\times~4~m$ perpendicular to the beamline. \n",
    "\n",
    "This corresponds to 3 √ó 6 EMCal super modules where:\n",
    "- 1 EMCal super module = 6 √ó 6 = 36 EMCal modules.\n",
    "- 1 EMCal module is 11 cm √ó 11 cm and contains 2 √ó 2 = 4 towers/channels, with a granularity of approximately 5.5 cm.\n",
    "\n",
    "In total, there are 2592 towers or channels to read out the energy deposits from the EMCal.\n",
    "\n",
    "For practical purposes, consider the PHENIX EMCal as a 2D matrix of 2592 channels (72 horizontal x 36 vertical), where each channel has a dimension of (5.535cm x 5.535cm x 36.96cm)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbd0329-4db4-465f-b450-0f65d496cae6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"figures/PHENIX_color_view.gif\" width=\"50%\">\n",
    "  <figcaption style=\"margin-top: 6px; font-size: 90%;\"> Schematic view of the PHENIX detector. </figcaption>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190b4dcb-402d-4cd9-b904-71bc9459e87b",
   "metadata": {},
   "source": [
    "We provide rootfiles containing the readout for electron and dielectron events from the EMCal.\n",
    "\n",
    "The readout has the following format:\n",
    "```\n",
    "'elmID': array([1207, 1208, 1243, 1244, 1245, 1246, 1279, 1280, 1281, 1282,\n",
    "       1283, 1314, 1315, 1316, 1317, 1318, 1352, 1387, 1388, 1389, 1390],\n",
    "       dtype=int32), \n",
    "'edep': array([2.1672759e-03, 2.3865167e-03, 6.9637364e-03, 6.5519638e-02,\n",
    "       5.9960117e-03, 1.5223619e-03, 1.5519783e-02, 1.3763729e+00,\n",
    "       1.7959915e-02, 1.1316873e-03, 2.6412117e-03, 1.1183993e-03,\n",
    "       3.0373151e-03, 1.8506199e-02, 5.9680296e-03, 1.2358509e-03,\n",
    "       1.5430434e-03, 1.2675102e-03, 8.8297541e-04, 8.7783835e-04,\n",
    "       1.5175857e-03],\n",
    "       dtype=float32)\n",
    "```\n",
    "\n",
    "where `elmID[X]` is the identifier ($\\textit{element ID}$) of the channel that measured a given $\\textit{energy deposit}$ `edep[X]`.\n",
    "\n",
    "The values of `elmID[X]` vary from 0 to 2591 (corresponding to the total number of channels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f4be8f-db61-423e-b818-83818a571c47",
   "metadata": {},
   "source": [
    "To conveniently read the rootfiles, we provide the `exercise3_utils.py` module.\n",
    "\n",
    "Use the following code snippet to read one event from the EMCal simulation:\n",
    "\n",
    "```\n",
    "# Example to obtain EMCal hits\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc  # This converts the energy depositions into GeV\n",
    "```\n",
    "\n",
    "When using `elmID, edep = ex3.get_hit_data()`, you will be asked to select which set of simulated events you want to use.\n",
    "We are providing one `electron.root` and one `dieletron.root` samples: digit `electron` or `dieletron` depending on what sample you want to access.\n",
    "\n",
    "In the rest of the exercise, whenever you are asked to work with the simulated events from the PHENIX EMCal, please also remember to always convert the energy depositions as above using `ex3.sfc`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21115aab",
   "metadata": {},
   "source": [
    "<a name='section_2_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.1: Events visualization and distribution</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbc650",
   "metadata": {},
   "source": [
    "The `elmID` is the index of the channel that received an hit and `edep` is the energy deposition measured for a hit in the given channel. \n",
    "To reconstruct the energy of the particle, you need to convert `elmID` into 2D spatial coordinates. \n",
    "Since each electron may deposit part of its energy in different neighboring cells, we typically want to assign to the electron the energy of the cell with maximum energy deposit plus the energy of the closest cells.\n",
    "\n",
    "Also, the energy deposited in the EMCal should be divided by a sampling fraction constant (`ex3.sfc`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420fb15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Write an algorithm that converts the channel ID into a pair of X and Y coordinates (in cm) according to the geometry of the PHENIX EMCal.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c2aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_channels_energies_to_matrix(channels, energies, n_rows=72, n_columns=36):\n",
    "    '''\n",
    "    This function is not ment to map into spatial coordinates,\n",
    "    but it is useful to cross-check the results.\n",
    "    '''\n",
    "\n",
    "def channel_to_spatial_coordinates(channels, n_rows=72, n_columns=36, channel_size=5.535):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9237c27",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Plot the 2D distribution of all hits in an event according to their X and Y coordinates and their energy deposition. For example, show event 5 from the electron sample.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52bcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_energy_matrix(matrix, title=\"EMCal clusters\", color_map=\"viridis\"):\n",
    "\n",
    "\n",
    "def plot_spatial_energy_matrix(coordinates, energies, centroids=None, labels=None, title=\"EMCal clusters\", marker_size_scale=20, color_map=\"viridis\"):\n",
    "    \n",
    "\n",
    "\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26be2f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> <br>\n",
    "- What is the measured energy of the particle in event 5 of the electron sample?  <br>\n",
    "- And what is the distribution of all measured energies in all events of the electron sample?  <br>\n",
    "  <strong> Hint </strong>: check 'exercise3_utils.py' to understand how to conveinently access events without the need of keyboard inputs.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e772f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5a490",
   "metadata": {},
   "source": [
    "<a name='section_2_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 2.2: Cluster properties and moments</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da7d49",
   "metadata": {},
   "source": [
    "After having measured the energy deposited by all the hits in a cluster, it is important to characterize the cluster and determine its properties. We will use the moments of a distribution to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57add0d-e88a-494f-ade7-832750c714d1",
   "metadata": {},
   "source": [
    "The moments of a distribution provide useful information about its shape and spread. Below are the formulas for different moments:\n",
    "- $\\textbf{1st order (raw)}$:\n",
    "    $$\n",
    "    \\text{Mean: } \\mu := \\mathbb{E}[X] = \\frac{\\mu_1}{1}\n",
    "    $$\n",
    "- $\\textbf{2nd order (central)}$:\n",
    "    $$\n",
    "    \\text{Variance: } \\sigma^2 = \\mathbb{E}[(X - \\mu)^2] = \\frac{\\mu_2}{1^2} = \\mu_2\n",
    "    $$\n",
    "- $\\textbf{3rd order (standardized)}$:\n",
    "    $$\n",
    "    \\text{Skewness: }\\gamma = \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right)^3 \\right] = \\frac{\\mathbb{E}[(X - \\mu)^3]}{(\\mathbb{E}[(X - \\mu)^2])^{3/2}}\n",
    "    $$\n",
    "- $\\textbf{4th order (standardized)}$:\n",
    "    $$\n",
    "    \\text{Kurtosis: } g = \\mathbb{E} \\left[ \\left( \\frac{X - \\mu}{\\sigma} \\right)^4 \\right] = \\frac{\\mathbb{E}[(X - \\mu)^4]}{(\\mathbb{E}[(X - \\mu)^2])^2}\n",
    "    $$\n",
    "\n",
    "They are helpful to analyze the 2D distribution of the EMCal hits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681e68a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Using $\\textit{numpy}$, implement functions to calculate the mean (geometric center), width ($\\sigma$), standardized skewness and standardized kurtosis for the PHENIX EMCal clusters.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd0b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to complete the following functions\n",
    "\n",
    "def f_mean(data):\n",
    "    ...\n",
    "    return mean\n",
    "\n",
    "\n",
    "def f_width(data):\n",
    "    ...\n",
    "    return width\n",
    "\n",
    "\n",
    "def f_variance(data):\n",
    "    ...\n",
    "    return variance\n",
    "\n",
    "\n",
    "def f_skewness(data):\n",
    "    ...\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis(data):\n",
    "    ...\n",
    "    return kurtosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ced72d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize again some events from the electron sample and calculate the moments. Which moments look useful for identifying electrons, and why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8496c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e1718f-eaf0-44fc-9371-16a4955f745e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3f9dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Standardization means rescaling data so that it has a mean of 0 and a standard deviation of 1.<br><br>\n",
    "Implement functions to calculate skewness and kurtosis without \"standardization\" and compute them for a few events. Why do we usually use the standardized versions?\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a37a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --> enter your code to complete the following functions\n",
    "\n",
    "def f_skewness_raw(data):\n",
    "    ...\n",
    "    return skewness\n",
    "\n",
    "\n",
    "def f_kurtosis_raw(data):\n",
    "    ...\n",
    "    return kurtosis\n",
    "\n",
    "\n",
    "# Skewness\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "\n",
    "x_skewness_raw = f_skewness_raw(x)\n",
    "y_skewness_raw = f_skewness_raw(y)\n",
    "print(f'Raw skewness: {x_skewness},{y_skewness}')\n",
    "\n",
    "# Kurtosis\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "\n",
    "x_kurtosis_raw = f_kurtosis_raw(x)\n",
    "y_kurtosis_raw = f_kurtosis_raw(y)\n",
    "print(f'Raw kurtosis: {x_kurtosis_raw},{y_kurtosis_raw}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15cd8f9-11d4-415e-a53d-ad15737657c6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123fc926",
   "metadata": {},
   "source": [
    "<a name='section_3_0'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h1 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Section 3: Calorimetry and clustering</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14556f-e6ee-4a4e-83f2-e15cfe644f85",
   "metadata": {},
   "source": [
    "Due to the complex patterns of particle interactions, EMCal readouts can become dense and chaotic.\n",
    "In these situations, clustering algorithms are essential to group hits that originate from a single particle, \n",
    "helping to reconstruct particle flows or analyze jets.\n",
    "\n",
    "The $K$-means algorithm is a popular unsupervised machine learning technique used to partition data into $K$ distinct clusters based on feature similarity. \n",
    "\n",
    "- $\\textbf{Initialize centroids}$: Randomly select $K$ hits; these hits will be the starting, $K$, centroids\n",
    "\n",
    "- $\\textbf{Assign clusters}$: Assign hits to the nearest centroid, forming $K$ clusters\n",
    "\n",
    "- $\\textbf{Update centroids and reassign hits}$: Calculate the centroid (mean of the coordinates) of each cluster; check if a hit in a cluster is closer to another centroid; if so, reallocate the hits to the closest cluster.\n",
    "\n",
    "- $\\textbf{Iterate}$: Repeat step 3 until no more hits change cluster (or until a certain tolerance).\n",
    "\n",
    "- $\\textbf{Output}$: The final centroids represent the centers of the $K$ clusters, and each hit is assigned to the cluster of its nearest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d80be",
   "metadata": {},
   "source": [
    "<a name='section_3_1'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.1: A homemade K-means clustering algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4614b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Visualize the event 0 from the electron sample and the event 6 from the dielectron sample and then compute the relevant moments. Do they still provide a good description for multi-particle cases? Why?</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event 0, electron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')\n",
    "\n",
    "# Event 6, dielectron\n",
    "elmID, edep = ex3.get_hit_data()\n",
    "edep = edep/ex3.sfc\n",
    "\n",
    "coordinates = channel_to_spatial_coordinates(elmID)\n",
    "\n",
    "x = coordinates[:, 0]\n",
    "y = coordinates[:, 1]\n",
    "\n",
    "plot_spatial_energy_matrix(coordinates, edep)\n",
    "\n",
    "print(x, y)\n",
    "x_mean = f_mean(x)\n",
    "y_mean = f_mean(y)\n",
    "print(f'Mean: {x_mean},{y_mean}')\n",
    "x_width = f_width(x)\n",
    "y_width = f_width(y)\n",
    "print(f'Width: {x_width},{y_width}')\n",
    "x_skewness = f_skewness(x)\n",
    "y_skewness = f_skewness(y)\n",
    "print(f'Skewness: {x_skewness},{y_skewness}')\n",
    "x_kurtosis = f_kurtosis(x)\n",
    "y_kurtosis = f_kurtosis(y)\n",
    "print(f'Kurtosis: {x_kurtosis},{y_kurtosis}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bef23b-c2c3-4b75-a660-79401dbe96aa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "\n",
    "*--> (put your text here)*\n",
    "\n",
    "Comment your results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03da784",
   "metadata": {},
   "source": [
    "For cases with particle gun decays, we can perform clustering to group the hits associated with different secondary particles produced in the decay.\n",
    "\n",
    "To test the clustering algorithms and evaluate if they are implemented correctly, you can use the following method to randomly generate a number of clusters with a given number of hits.\n",
    "\n",
    "```\n",
    "import ex3\n",
    "points = ex3.generate_2d_points()\n",
    "# ex3.generate_2d_points(num_clusters=X, points_per_cluster=Y, spread=Z, random_seed=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7721df28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Generate some points with the default settings (without passing arguments) and also with some custom settings and visualize the generated datasets.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7acae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_points(num_clusters, points_per_cluster, spread, random_seed=42):\n",
    "    np.random.seed(random_seed)\n",
    "    data = []\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        center = np.random.uniform([-120, -60], [120, 60])\n",
    "        cluster_points = center + np.random.randn(points_per_cluster, 2) * spread\n",
    "        data.append(cluster_points)\n",
    "\n",
    "    data = np.vstack(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_constant_array(array, constant=1):\n",
    "    return np.full(array.shape[0], constant)\n",
    "\n",
    "\n",
    "i=0\n",
    "for n in [2, 4, 6]:\n",
    "    for p in [10, 20, 30]:\n",
    "        for s in [1., 3., 5.]:\n",
    "            i+=1\n",
    "            coordinates = generate_2d_points(num_clusters=n, points_per_cluster=p, spread=s, random_seed=i)\n",
    "            energies = get_constant_array(array=coordinates, constant=1)\n",
    "            plot_spatial_energy_matrix(coordinates=coordinates, energies=energies, title=f'Clusters: {n}, Points per clusters: {p}, Spread: {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b267cd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "<h3>üß© Exercise: K-Means Clustering</h3>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>What is Cluster Analysis?</h4>\n",
    "\n",
    "<p>\n",
    "Cluster analysis is the process of <strong>grouping together similar points into clusters</strong>.\n",
    "A <em>point</em> can have 2, 3, or even hundreds of dimensions ‚Äî meaning it‚Äôs a vector in some space.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "One practical example is <strong>epidemiological clustering</strong>:\n",
    "you might have 2D points representing the <strong>longitude and latitude</strong> of locations where birds carrying different strains of avian flu were found.\n",
    "By clustering these points, you can gain insight into which regions correspond to each strain.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Distances Between Points</h4>\n",
    "\n",
    "<p>\n",
    "To cluster data, we must measure <strong>how close or far</strong> points are from each other.\n",
    "The <strong>Euclidean distance</strong> is the most common measure.\n",
    "</p>\n",
    "\n",
    "<p>For two 2D points:</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2}\n",
    "\\]\n",
    "\n",
    "<p>For two 3D points:</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2 + (p_z - q_z)^2}\n",
    "\\]\n",
    "\n",
    "<p>In general, for two \\(n\\)-dimensional points\n",
    "\\(p = (p_1, p_2, \\dots, p_n)\\) and \\(q = (q_1, q_2, \\dots, q_n)\\):</p>\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2}\n",
    "\\]\n",
    "\n",
    "<p><strong>Example:</strong></p>\n",
    "\\[\n",
    "p = (0.1, 0.2, 0.3, 0.4), \\quad q = (0.0, 0.2, 0.3, 0.2)\n",
    "\\]\n",
    "\\[\n",
    "d(p, q) = \\sqrt{(0.1-0.0)^2 + (0.2-0.2)^2 + (0.3-0.3)^2 + (0.4-0.2)^2} = 0.7071\\ldots\n",
    "\\]\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Cluster Centroids</h4>\n",
    "\n",
    "<p>\n",
    "The <strong>centroid</strong> of a cluster is its <em>center of mass</em> ‚Äî the <strong>average position</strong> of all points in that cluster.\n",
    "Even though it‚Äôs the mean of all cluster points, the centroid does <em>not</em> need to be one of those points.\n",
    "</p>\n",
    "\n",
    "<p>To compute a centroid:</p>\n",
    "\\[\n",
    "\\text{centroid} = \\frac{1}{N} \\sum_{i=1}^{N} p_i\n",
    "\\]\n",
    "\n",
    "<p>Vector operations:</p>\n",
    "\\[\n",
    "p + q = (p_1 + q_1,\\, p_2 + q_2,\\, \\dots,\\, p_n + q_n)\n",
    "\\]\n",
    "\\[\n",
    "\\frac{p}{a} = \\left(\\frac{p_1}{a},\\, \\frac{p_2}{a},\\, \\dots,\\, \\frac{p_n}{a}\\right)\n",
    "\\]\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>The K-Means Algorithm</h4>\n",
    "\n",
    "<p>\n",
    "The <strong>idea</strong> behind K-Means is simple:\n",
    "each point belongs to the cluster whose centroid (mean) it is <strong>closest</strong> to.\n",
    "Because centroids depend on which points are assigned to them, and assignments depend on centroids, we solve this <em>chicken-and-egg</em> problem iteratively.\n",
    "</p>\n",
    "\n",
    "<h5>Step 1. Pick \\(k\\) Centroids</h5>\n",
    "\n",
    "<p>\n",
    "We start by choosing \\(k\\), the number of clusters we want.\n",
    "Each centroid \\(m_j\\) is an \\(n\\)-dimensional point:\n",
    "</p>\n",
    "\\[\n",
    "m_j = (m_{j,1}, m_{j,2}, \\dots, m_{j,n})\n",
    "\\]\n",
    "<p>\n",
    "We randomly select \\(k\\) points from the dataset as our <strong>initial centroids</strong>\n",
    "(the <em>Forgy method</em>).\n",
    "</p>\n",
    "\n",
    "<h5>Step 2. Partition the Dataset</h5>\n",
    "\n",
    "<p>\n",
    "Assign each point to the <strong>nearest centroid</strong> by Euclidean distance.\n",
    "If a point is equally close to multiple centroids, break ties arbitrarily.\n",
    "This produces \\(k\\) sets \\(S_1, S_2, \\dots, S_k\\),\n",
    "where each \\(S_j\\) contains all points closest to centroid \\(m_j\\).\n",
    "</p>\n",
    "\n",
    "<h5>Step 3. Recompute the Means</h5>\n",
    "\n",
    "<p>For each cluster \\(S_j\\), recompute its centroid:</p>\n",
    "\\[\n",
    "m_j = \\frac{1}{|S_j|} \\sum_{q \\in S_j} q\n",
    "\\]\n",
    "<p>\n",
    "Since centroids have changed, some points may now be closer to a different centroid ‚Äî\n",
    "so we repeat the assignment step.\n",
    "</p>\n",
    "\n",
    "<h5>Step 4. Repeat Until Convergence</h5>\n",
    "\n",
    "<ul>\n",
    "  <li>The centroids stop moving, or</li>\n",
    "  <li>The assignments no longer change.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "Sometimes convergence takes many iterations, so we often set a\n",
    "<strong>maximum iteration limit</strong> to prevent infinite loops.\n",
    "</p>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<h4>Summary of the K-Means Algorithm</h4>\n",
    "\n",
    "<ol>\n",
    "  <li>Choose \\(k\\) and initialize centroids randomly.</li>\n",
    "  <li>Assign each point to the nearest centroid.</li>\n",
    "  <li>Recompute each centroid as the mean of its assigned points.</li>\n",
    "  <li>Repeat steps 2‚Äì3 until centroids stop changing or max iterations reached.</li>\n",
    "</ol>\n",
    "\n",
    "<hr>\n",
    "\n",
    "<p><strong>‚úÖ Key Idea:</strong>  \n",
    "K-Means minimizes the <em>within-cluster sum of squared errors</em> (inertia) ‚Äî  \n",
    "the total squared distance between points and their assigned centroids.</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad69ab-3530-4b45-9461-29d712c19312",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Fill the missing parts in the following class to implement the k-means algorithm.\n",
    "</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bb083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Minimal NumPy-only implementation of the K-Means clustering algorithm.\n",
    "\n",
    "    This class groups data points into `n_clusters` clusters by repeatedly\n",
    "    performing two steps:\n",
    "      1. Assign each point to the nearest cluster center (centroid).\n",
    "      2. Recompute each centroid as the mean of the points assigned to it.\n",
    "\n",
    "    The process stops when either:\n",
    "      - The centroids stop moving (i.e., total movement < `tol`), or\n",
    "      - The maximum number of iterations (`max_iter`) is reached.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "        Number of clusters (K). Must be >= 1.\n",
    "    init : {\"k-means++\", \"random\"}\n",
    "        Initialization scheme for the centroids.\n",
    "        - \"random\": pick K random points from the data as initial centroids.\n",
    "        - \"k-means++\": smarter initialization that spreads out initial centroids.\n",
    "    max_iter : int\n",
    "        Maximum number of K-Means iterations (assign + update steps).\n",
    "    tol : float\n",
    "        Convergence tolerance on centroid shift (Euclidean norm).\n",
    "        If the total movement of all centroids is less than this value,\n",
    "        the algorithm stops early.\n",
    "    random_state : int or None\n",
    "        Seed for random number generators (both Python's `random` and NumPy's).\n",
    "        Use this for reproducible results.\n",
    "\n",
    "    Attributes (set after calling fit)\n",
    "    ----------------------------------\n",
    "    cluster_centers_ : ndarray of shape (n_clusters, n_features)\n",
    "        Final positions of the cluster centroids.\n",
    "    labels_ : ndarray of shape (n_samples,)\n",
    "        Cluster index (0 to n_clusters-1) assigned to each sample in X.\n",
    "    inertia_ : float\n",
    "        Final value of the K-Means objective:\n",
    "        sum of squared distances of each point to its assigned centroid.\n",
    "    n_iter_ : int\n",
    "        Number of iterations run until convergence (or reaching max_iter).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=None):\n",
    "        self.n_clusters   = int(n_clusters)\n",
    "        self.init         = init\n",
    "        self.max_iter     = int(max_iter)\n",
    "        self.tol          = float(tol)\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Attributes set after fitting\n",
    "        self.cluster_centers_ = None  # centroids after fitting\n",
    "        self.labels_          = None  # cluster labels for each sample\n",
    "        self.inertia_         = None  # final within-cluster sum of squares\n",
    "        self.n_iter_          = None  # number of iterations performed\n",
    "\n",
    "    # ---------- core primitives ----------\n",
    "\n",
    "    def _euclidean_squared(self, a, b):\n",
    "        \"\"\"\n",
    "        Compute squared Euclidean distances between two sets of vectors.\n",
    "\n",
    "        This is a vectorized computation of:\n",
    "            dist^2(a[i], b[j]) = ||a[i] - b[j]||^2\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        a : ndarray of shape (n_samples, n_features)\n",
    "            First set of vectors (e.g., data points).\n",
    "        b : ndarray of shape (n_centroids, n_features)\n",
    "            Second set of vectors (e.g., centroids).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        d2 : ndarray of shape (n_samples, n_centroids)\n",
    "            d2[i, j] is the squared distance between a[i] and b[j].\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        We avoid explicit Python loops by using the identity:\n",
    "            ||x - y||^2 = ||x||^2 - 2 x¬∑y + ||y||^2\n",
    "        computed in a fully vectorized way.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return a2 - 2.0 * ab + b2\n",
    "\n",
    "    def _kmeanspp_init(self, X, rng):\n",
    "        \"\"\"\n",
    "        Initialize centroids using the k-means++ algorithm.\n",
    "\n",
    "        The idea:\n",
    "          1. Choose one initial centroid uniformly at random from X.\n",
    "          2. For each remaining centroid:\n",
    "             - Compute the distance of each point to its closest chosen centroid.\n",
    "             - Choose the next centroid at random, with probability proportional\n",
    "               to distance^2 (points far away from existing centroids are more\n",
    "               likely to be chosen).\n",
    "\n",
    "        This tends to produce better (more spread out) initial centroids than\n",
    "        simple random selection.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        rng : np.random.Generator\n",
    "            NumPy random number generator (already seeded).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Initial centroid positions.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "\n",
    "        return centroids\n",
    "\n",
    "    # ---------- step-by-step methods ----------\n",
    "\n",
    "    def _initialize_centroids(self, X, rng=None):\n",
    "        \"\"\"\n",
    "        Step 2: Initialize centroids before starting the K-Means iterations.\n",
    "\n",
    "        For this implementation, we use simple random initialization:\n",
    "        we pick K distinct samples from X and use them as the initial centroids.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        rng : np.random.Generator or None\n",
    "            Unused here (kept for API symmetry with other methods).\n",
    "            Python's built-in `random` module is used instead.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Initial centroid positions chosen from the data points.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - If `random_state` is provided in the constructor, we seed the Python\n",
    "          `random` module to make the choice of initial points reproducible.\n",
    "        - This method currently ignores the `init` parameter and always uses\n",
    "          random initialization. A more advanced version could switch between\n",
    "          this and `_kmeanspp_init`.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return centroids\n",
    "\n",
    "    def _assign(self, X, centroids):\n",
    "        \"\"\"\n",
    "        Step 3: Assignment step ‚Äî assign each point to the nearest centroid.\n",
    "\n",
    "        For each sample x_i in X, we find the centroid c_j that minimizes\n",
    "        the squared Euclidean distance ||x_i - c_j||^2, and assign x_i\n",
    "        to cluster j.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Current centroid positions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            labels[i] is the index (0..K-1) of the closest centroid to X[i].\n",
    "        d2 : ndarray of shape (n_samples, n_clusters)\n",
    "            Squared distances from each point to each centroid.\n",
    "            d2[i, j] = ||X[i] - centroids[j]||^2.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The actual assignment only uses the argmin of distances, but we also\n",
    "        return the full distance matrix `d2` as it can be useful for analysis.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return labels, d2\n",
    "\n",
    "    def _update(self, X, labels, rng):\n",
    "        \"\"\"\n",
    "        Step 4: Update step ‚Äî recompute centroids from current assignments.\n",
    "\n",
    "        For each cluster j, we:\n",
    "          - Collect all points assigned to cluster j.\n",
    "          - Compute their mean along each feature dimension.\n",
    "          - Use this mean vector as the new centroid for cluster j.\n",
    "\n",
    "        If a cluster becomes \"empty\" (i.e., no points are assigned to it),\n",
    "        we handle it by re-seeding that centroid to a random point from X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index for each sample.\n",
    "        rng : np.random.Generator\n",
    "            NumPy random number generator (already seeded), used to\n",
    "            handle empty clusters by choosing a random point.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        new_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Updated centroid positions after recomputing means.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Empty cluster handling is important: K-Means sometimes creates\n",
    "        clusters that end up with no assigned points. Without re-seeding,\n",
    "        we would get NaNs or invalid centroids.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "       \n",
    "        return new_centroids\n",
    "\n",
    "    def _converged(self, old_centroids, new_centroids, old_labels, new_labels):\n",
    "        \"\"\"\n",
    "        Step 5: Convergence check ‚Äî decide whether to stop iterating.\n",
    "\n",
    "        We consider two possible convergence criteria:\n",
    "\n",
    "          1. Label stability:\n",
    "             If cluster assignments (labels) do not change between two\n",
    "             consecutive iterations (`old_labels == new_labels`), the\n",
    "             algorithm has reached a stable clustering.\n",
    "\n",
    "          2. Centroid movement:\n",
    "             We compute the total movement of centroids as the Euclidean norm\n",
    "             of the difference between old and new centroids:\n",
    "                 shift = ||new_centroids - old_centroids||_F\n",
    "             (Frobenius norm). If `shift < tol`, we also stop.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        old_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Centroids from the previous iteration.\n",
    "        new_centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Centroids from the current iteration.\n",
    "        old_labels : ndarray of shape (n_samples,) or None\n",
    "            Cluster labels from the previous iteration (None on first iteration).\n",
    "        new_labels : ndarray of shape (n_samples,)\n",
    "            Cluster labels from the current iteration.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        converged : bool\n",
    "            True if convergence criteria are met, False otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "        \n",
    "        return shift < self.tol\n",
    "\n",
    "    def _compute_inertia(self, X, labels, centroids):\n",
    "        \"\"\"\n",
    "        Step 6: Compute inertia (within-cluster sum of squared errors).\n",
    "\n",
    "        Inertia is the K-Means objective function:\n",
    "            inertia = sum_i ||X[i] - centroids[labels[i]]||^2\n",
    "\n",
    "        Lower inertia means that points are, on average, closer to their\n",
    "        assigned centroids (tighter clusters).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, n_features)\n",
    "            Input data.\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index for each sample.\n",
    "        centroids : ndarray of shape (n_clusters, n_features)\n",
    "            Final centroids.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        inertia : float\n",
    "            Sum of squared distances from points to their assigned centroids.\n",
    "        \"\"\"\n",
    "\n",
    "        # implement this function\n",
    "        \n",
    "        return inertia\n",
    "    # ---------- public API ----------\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Run K-Means clustering on the dataset X.\n",
    "\n",
    "        This method performs the full algorithm:\n",
    "          1. Initialize centroids.\n",
    "          2. Repeat until convergence or reaching max_iter:\n",
    "             a. Assign each point to the nearest centroid.\n",
    "             b. Update centroids as means of assigned points.\n",
    "             c. Check for convergence.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input data to be clustered. Will be converted to a NumPy array\n",
    "            of dtype float.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : KMeans\n",
    "            The fitted instance (for method chaining).\n",
    "\n",
    "        Side effects\n",
    "        ------------\n",
    "        After calling fit, the following attributes are set:\n",
    "          - self.cluster_centers_\n",
    "          - self.labels_\n",
    "          - self.inertia_\n",
    "          - self.n_iter_\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Assign cluster labels to new data points using fitted centroids.\n",
    "\n",
    "        This does **not** run the K-Means algorithm again; it simply\n",
    "        assigns each new point to the nearest existing centroid from\n",
    "        `self.cluster_centers_`.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            New data points to assign to clusters.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index (0..K-1) for each row of X.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        RuntimeError\n",
    "            If the model has not been fitted yet (i.e. `fit` has not been called).\n",
    "        \"\"\"\n",
    "        \n",
    "        # implement this function\n",
    "        \n",
    "        return labels\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Convenience method: fit the model on X and return cluster labels.\n",
    "\n",
    "        This is equivalent to:\n",
    "            kmeans.fit(X)\n",
    "            labels = kmeans.labels_\n",
    "\n",
    "        but implemented as a single method for convenience.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input data to cluster.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        labels : ndarray of shape (n_samples,)\n",
    "            Cluster index assigned to each sample in X.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00df5cd0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 1:</strong> \n",
    "use the cell below to evalue inertia and iterations K-Means you have implemented</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5f5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ---- Load Iris dataset ----\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "# ---- Your implementation ----\n",
    "my_km = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=34)\n",
    "my_labels = my_km.fit_predict(X)\n",
    "\n",
    "print(\"=== Your KMeans ===\")\n",
    "print(f\"Iterations: {my_km.n_iter_}\")\n",
    "print(f\"Inertia: {my_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, my_labels):.4f}\")\n",
    "\n",
    "# ---- scikit-learn implementation ----\n",
    "sk_km = SKKMeans(n_clusters=3, init=\"k-means++\", n_init=1, max_iter=300, tol=1e-4,\n",
    "                 algorithm=\"lloyd\", random_state=42)\n",
    "sk_labels = sk_km.fit_predict(X)\n",
    "\n",
    "print(\"\\n=== scikit-learn KMeans ===\")\n",
    "print(f\"Iterations: {sk_km.n_iter_}\")\n",
    "print(f\"Inertia: {sk_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, sk_labels):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c8f83",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Unit test 2:</strong> \n",
    "Import the external unit test, check if home-brewed K-Means has passed all the test</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a183f5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i unit_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37abc2d",
   "metadata": {},
   "source": [
    "<a name='section_3_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.2: Finding optimal number of centroids</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9947f4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong><br>\n",
    "The <em>elbow method</em> is a common technique for choosing the optimal number of clusters <code>K</code> in K-means.  \n",
    "It works by computing a clustering quality measure (typically the Within-Cluster Sum of Squares, WCSS) for different values of <code>K</code>, and then plotting the score as a function of <code>K</code>.  \n",
    "As <code>K</code> increases, WCSS always decreases, but after a certain point the improvement becomes very small ‚Äî this ‚Äúelbow‚Äù in the curve suggests a good choice for <code>K</code>.\n",
    "\n",
    "Implement the elbow method <strong>yourself</strong> using your own K-means implementation:  \n",
    "1. Run K-means for a range of values (e.g. <code>K = 2...</code>)  \n",
    "2. Compute WCSS for each run  \n",
    "3. Plot WCSS vs. K and identify the ‚Äúelbow‚Äù  \n",
    "4. Test your method on several synthetic events to evaluate its performance.\n",
    "\n",
    "For background reading, see the Wikipedia article:  \n",
    "<a href=\"https://en.wikipedia.org/wiki/Elbow_method_(clustering)\" target=\"_blank\">Elbow Method (Wikipedia)</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a268a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_method(data, score_method, title_label, min_k=1, max_k=10):\n",
    "    \"\"\"\n",
    "    Evaluate a clustering quality score for different numbers of clusters K\n",
    "    and visualize both:\n",
    "      1) The clustering in 2D for each K.\n",
    "      2) How the score changes as a function of K (Elbow-style plot).\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1. Loop over K from min_k to max_k.\n",
    "    2. For each K:\n",
    "       - Run k-means to get centroids and labels.\n",
    "       - Compute a clustering score using `score_method`.\n",
    "       - Plot the clustered data in 2D with colors for each cluster and\n",
    "         centroids drawn on top.\n",
    "       - Store the score in a list.\n",
    "    3. After the loop, plot \"score vs K\" to help choose the optimal K.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        Input data points to be clustered.\n",
    "    score_method : callable\n",
    "        Function that takes (data, centroids, labels) and returns a numeric\n",
    "        score (e.g., WCSS). Lower or higher is \"better\" depending on the\n",
    "        method.\n",
    "    title_label : str\n",
    "        Label used in plot titles (e.g. \"Elbow method\").\n",
    "    min_k : int, default=1\n",
    "        Minimum number of clusters to evaluate.\n",
    "    max_k : int, default=10\n",
    "        Maximum number of clusters to evaluate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score_values : list of float\n",
    "        List of scores, where score_values[i] corresponds to\n",
    "        K = min_k + i.\n",
    "    \"\"\"\n",
    "    score_values = []\n",
    "\n",
    "    # After evaluating all K, plot score as a function of K (Elbow plot)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(range(min_k, max_k + 1), score_values, marker='o', linestyle='--')\n",
    "    plt.title(f\"{title_label} method for the optimal K\")\n",
    "    plt.xlabel(\"Number of clusters (K)\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.show()\n",
    "\n",
    "    return score_values\n",
    "\n",
    "\n",
    "def wcss_score(data, centroids, labels):\n",
    "    \"\"\"\n",
    "    Compute WCSS (Within-Cluster Sum of Squares) for a given clustering.\n",
    "\n",
    "    WCSS is defined as:\n",
    "        sum over all clusters i of\n",
    "            sum over all points x in cluster i of\n",
    "                ||x - centroid_i||^2\n",
    "\n",
    "    Intuitively:\n",
    "      - For each cluster, we measure how far its points are from the cluster\n",
    "        centroid (squared distance).\n",
    "      - We sum all these squared distances.\n",
    "      - Lower WCSS means more compact, tighter clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        Input data points.\n",
    "    centroids : ndarray of shape (k, n_features)\n",
    "        Centroid coordinates for each cluster.\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        labels[j] is the index (0..k-1) of the cluster assigned to data[j].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    wcss : float\n",
    "        Total within-cluster sum of squared distances.\n",
    "    \"\"\"\n",
    "    wcss = 0.0\n",
    "\n",
    "    return wcss\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Example usage: generate synthetic data with different true numbers\n",
    "# of clusters and run the \"Elbow method\" evaluation.\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "for n in [2, 4, 6]:\n",
    "    print('###############################################################################################')\n",
    "    print(f'Generating {n} clusters...')\n",
    "\n",
    "    # Generate a 2D dataset with `n` well-separated clusters\n",
    "    coordinates = generate_2d_points(\n",
    "        num_clusters=n,\n",
    "        points_per_cluster=20,\n",
    "        spread=4.0,\n",
    "        random_seed=999\n",
    "    )\n",
    "\n",
    "    # Evaluate WCSS for K = 2..10 and visualize clusters + elbow plot\n",
    "    evaluate_method(\n",
    "        data=coordinates,\n",
    "        score_method=wcss_score,\n",
    "        title_label='Elbow method',\n",
    "        min_k=2,\n",
    "        max_k=10\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d95e60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong><br>\n",
    "The <em>silhouette method</em> is a technique for evaluating how well data points fit within their assigned clusters.  \n",
    "For each point, the silhouette score compares:\n",
    "<ul>\n",
    "  <li>how close it is to points within its own cluster, and</li>\n",
    "  <li>how far it is from points in the nearest other cluster.</li>\n",
    "</ul>\n",
    "The score ranges from -1 to +1: values near +1 indicate well-separated, meaningful clusters, while values near 0 suggest overlapping clusters.\n",
    "\n",
    "Implement the silhouette method <strong>yourself</strong> for your K-means algorithm:\n",
    "<ol>\n",
    "  <li>Compute the silhouette score for every data point.</li>\n",
    "  <li>Average these scores to obtain the silhouette score for the whole dataset.</li>\n",
    "  <li>Evaluate this score for several different values of <code>K</code>.</li>\n",
    "  <li>Apply the method to a few synthetic events and assess how well it identifies the correct number of clusters.</li>\n",
    "</ol>\n",
    "\n",
    "For more details, see the Wikipedia article:  \n",
    "<a href=\"https://en.wikipedia.org/wiki/Silhouette_(clustering)\" target=\"_blank\">Silhouette (clustering)</a>.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e2645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette_score(data, centroids, labels):\n",
    "    \"\"\"\n",
    "    Compute the Silhouette Score for a given clustering.\n",
    "\n",
    "    The silhouette score measures how well each point fits within its cluster\n",
    "    compared to other clusters. It ranges from:\n",
    "        -1  ‚Üí very poor clustering (point is closer to another cluster)\n",
    "         0  ‚Üí ambiguous / overlapping clusters\n",
    "         1  ‚Üí very good clustering (point well inside its own cluster)\n",
    "\n",
    "    For each point i:\n",
    "        a_i = average distance to other points in its own cluster\n",
    "        b_i = lowest average distance to points in any *other* cluster\n",
    "        s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "\n",
    "    The overall silhouette score is the average over all s_i.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray of shape (n_samples, n_features)\n",
    "        The dataset being clustered.\n",
    "    centroids : ndarray of shape (k, n_features)\n",
    "        Centroid positions for the k clusters. (Not directly used here.)\n",
    "    labels : ndarray of shape (n_samples,)\n",
    "        labels[i] = index of the cluster assigned to data[i].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The average silhouette score for the entire clustering.\n",
    "        Higher is better (best value is +1).\n",
    "    \"\"\"\n",
    "\n",
    "    total_score = 0\n",
    "    n_samples = data.shape[0]\n",
    "    k = len(centroids)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        point = data[i]\n",
    "        point_label = labels[i]\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 1: Compute a_i = average intra-cluster distance\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "        # Step 2: Compute b_i = closest *other* cluster\n",
    "        # For each other cluster j, compute the average distance to j.\n",
    "        # ------------------------------------------------------------\n",
    "       \n",
    "        # ------------------------------------------------------------\n",
    "        # Step 3: Compute silhouette value for this point\n",
    "        # s_i = (b_i - a_i) / max(a_i, b_i)\n",
    "        # ------------------------------------------------------------\n",
    "        \n",
    "\n",
    "    # ------------------------------------------------------------\n",
    "    # Final Step: Return average silhouette score over all points\n",
    "    # ------------------------------------------------------------\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02eb580",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "Compare computational complexity for elbow and silhouette, and give your reasoning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57425f-5eab-4751-99c2-04d012f09012",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3f62e35",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "For particle physics, what tricks you can come up to reduce the computation complexity of number and coordination for the centroids</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900bdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_search(channels, energies, min_energy_threshold=5.0, padding_size=1, n_rows=72, n_columns=36):\n",
    "    # Step 1: Map energies to the 2D energy matrix\n",
    "\n",
    "    # Step 2: Apply minimum energy threshold to identify potential seed candidates\n",
    "    # Creating a binary mask where energy values are greater than the threshold\n",
    "\n",
    "    # Step 3: Get the coordinates of the potential seeds\n",
    "\n",
    "    # Step 4: Sort seeds by their energy values (ascending)\n",
    "\n",
    "\n",
    "    # Step 5: Define a padding region and check for neighboring cells with higher energy\n",
    "        # Extract the neighboring region (within bounds)\n",
    "        # If any neighboring cell has energy greater than the current seed, discard it\n",
    "\n",
    "        # Otherwise, keep this seed\n",
    "\n",
    "    return valid_seeds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab48d5",
   "metadata": {},
   "source": [
    "<a name='section_3_2'></a>\n",
    "<hr style=\"height: 1px;\">\n",
    "\n",
    "\n",
    "## <h3 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #FFA500\">Problem 3.3: Resolution of EM Calorimeter</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f05af",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<strong>Exercise:</strong> \n",
    "\n",
    "#  **B4d Calorimeter Geometry Overview**\n",
    "\n",
    "B4d defines a **longitudinal sampling electromagnetic calorimeter**:\n",
    "a stack of alternating **absorber** and **active (gap)** layers, just like B4b, but with **sensitive detectors** and **scorers** automatically attached.\n",
    "\n",
    "---\n",
    "\n",
    "##  **Geometric parameters (default values)**\n",
    "\n",
    "| Quantity                     | Symbol          | Default Value         | Description                                |\n",
    "| ---------------------------- | --------------- | --------------------- | ------------------------------------------ |\n",
    "| Number of layers             | `nofLayers`     | 10                    | Number of absorber + gap pairs             |\n",
    "| Absorber thickness           | `absoThickness` | 10 mm                 | Thickness of lead absorber per layer       |\n",
    "| Gap (active layer) thickness | `gapThickness`  | 5 mm                  | Thickness of liquid argon gap per layer    |\n",
    "| Calorimeter transverse size  | `calorSizeXY`   | 10 cm √ó 10 cm         | Square cross-section perpendicular to beam |\n",
    "| World volume size            | `1.2√ó` larger   | 12 cm √ó 12 cm √ó 18 cm | Vacuum surrounding the calorimeter         |\n",
    "\n",
    "---\n",
    "\n",
    "##  **Material composition**\n",
    "\n",
    "| Volume          | Material            | Notes                                             |\n",
    "| --------------- | ------------------- | ------------------------------------------------- |\n",
    "| **Absorber**    | `G4_Pb` (lead)      | Dense converter for e‚Åª/Œ≥ showers                  |\n",
    "| **Gap**         | `liquidArgon`       | Active readout medium (collects deposited energy) |\n",
    "| **World**       | `Galactic` (vacuum) | Empty container for geometry                      |\n",
    "| **Calorimeter** | (composite)         | Logical container holding 10 layers               |\n",
    "\n",
    "---\n",
    "\n",
    "##  **Structure (Z-axis stacking)**\n",
    "\n",
    "Each layer consists of:\n",
    "\n",
    "```\n",
    "|<--- Layer (15 mm) ----------------------------->|\n",
    "|                                                 |\n",
    "|   [ Absorber (Pb) | 10 mm ]  +  [ Gap (LAr) | 5 mm ] |\n",
    "```\n",
    "\n",
    "Stack 10 such layers along **+z** (the beam direction), producing a total depth of **150 mm**.\n",
    "\n",
    "### Schematic:\n",
    "\n",
    "```\n",
    "  e‚Åª beam ‚Üí\n",
    "            |##########|-----|##########|-----|##########|-----|\n",
    "            |  Pb (10) | LAr |  Pb (10) | LAr |  Pb (10) | LAr |\n",
    "            |##########|-----|##########|-----|##########|-----|\n",
    "                    <----------- repeated 10 times ----------->\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  **World hierarchy**\n",
    "\n",
    "| Level | Volume name   | Parent        | Description            |\n",
    "| ----- | ------------- | ------------- | ---------------------- |\n",
    "| 0     | `World`       | ‚Äî             | Vacuum box             |\n",
    "| 1     | `Calorimeter` | `World`       | Container of layers    |\n",
    "| 2     | `Layer`       | `Calorimeter` | Replicated 10√ó along z |\n",
    "| 3     | `Abso`        | `Layer`       | Lead absorber          |\n",
    "| 3     | `Gap`         | `Layer`       | Liquid argon gap       |\n",
    "\n",
    "---\n",
    "\n",
    "#  **Physical meaning**\n",
    "\n",
    "* **Absorber (Pb):** Converts incident e‚Åª or Œ≥ into a cascade of secondary particles via bremsstrahlung and pair production.\n",
    "* **Gap (LAr):** Collects the energy deposits of the shower particles; this ‚Äúvisible energy‚Äù is your calorimeter signal.\n",
    "* Each layer combination corresponds to one **sampling unit**.\n",
    "* Total thickness (~150 mm) gives about **15 radiation lengths**, enough to contain a several-GeV electromagnetic shower.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fff5f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, shutil, pathlib, textwrap, os\n",
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- CONFIG ----\n",
    "EXE = \"exampleB4d.py\"     # <- use the B4d example\n",
    "N_EVENTS = 100           # bump stats for smoother œÉ/E\n",
    "energies_GeV = [1, 2, 5, 10, 20, 50]\n",
    "\n",
    "# ---- RUN ONE ENERGY AND RENAME OUTPUT ----\n",
    "def run_one_energy(E):\n",
    "    mac = pathlib.Path(f\"run_{E}GeV.mac\")\n",
    "    mac.write_text(textwrap.dedent(f\"\"\"\n",
    "        /run/initialize\n",
    "        /gun/particle e-\n",
    "        /gun/energy {E} GeV\n",
    "        /run/printProgress 1000\n",
    "        /run/beamOn {N_EVENTS}\n",
    "    \"\"\").strip())\n",
    "\n",
    "    # ensure no leftover file from previous run\n",
    "    if pathlib.Path(\"B4.root\").exists():\n",
    "        os.remove(\"B4.root\")\n",
    "\n",
    "    # run the example in batch mode with this macro\n",
    "    subprocess.run([\"python\", EXE, \"-m\", str(mac)], check=True)\n",
    "\n",
    "    # the example writes B4.root; rename to per-energy file\n",
    "    src = pathlib.Path(\"B4.root\")\n",
    "    if not src.exists():\n",
    "        raise FileNotFoundError(\"Expected B4.root not found. Did the run finish?\")\n",
    "    dst = pathlib.Path(f\"B4_{E}GeV.root\")\n",
    "    shutil.move(str(src), str(dst))\n",
    "    return str(dst)\n",
    "\n",
    "# run all energies\n",
    "roots = [run_one_energy(E) for E in energies_GeV]\n",
    "print(\"Wrote:\", roots)\n",
    "\n",
    "# ---- LOAD Edep IN GAP (VISIBLE ENERGY) ----\n",
    "def load_edep_gap(root_path):\n",
    "    with uproot.open(root_path) as f:\n",
    "        t = f[\"B4\"]                    # TTree name\n",
    "        Egap = t[\"Egap\"].array(library=\"np\")  # MeV\n",
    "    return Egap\n",
    "\n",
    "means, sigmas, resolutions = [], [], []\n",
    "for E, rfile in zip(energies_GeV, roots):\n",
    "    Egap = load_edep_gap(rfile)       # MeV per event\n",
    "    mu   = Egap.mean()                # MeV\n",
    "    sig  = Egap.std(ddof=1)           # MeV\n",
    "    R    = sig / mu                   # dimensionless\n",
    "    means.append(mu)\n",
    "    sigmas.append(sig)\n",
    "    resolutions.append(R)\n",
    "\n",
    "means  = np.array(means)\n",
    "sigmas = np.array(sigmas)\n",
    "R      = np.array(resolutions)\n",
    "E      = np.array(energies_GeV, dtype=float)\n",
    "\n",
    "# ---- FIT R(E) = sqrt(a^2/E + b^2) VIA LINEARIZATION ----\n",
    "x = 1.0 / E\n",
    "y = R**2\n",
    "A = np.vstack([x, np.ones_like(x)]).T\n",
    "m, c = np.linalg.lstsq(A, y, rcond=None)[0]  # y ‚âà m x + c\n",
    "a = float(np.sqrt(max(m, 0.0)))  # stochastic term (‚àöGeV units)\n",
    "b = float(np.sqrt(max(c, 0.0)))  # constant term\n",
    "\n",
    "print(f\"a = {a*100:.1f}%¬∑‚àöGeV\")\n",
    "print(f\"b = {b*100:.2f}%\")\n",
    "\n",
    "# ---- PLOT ----\n",
    "E_dense = np.linspace(E.min(), E.max(), 200)\n",
    "R_fit = np.sqrt( (a*a)/E_dense + b*b )\n",
    "\n",
    "plt.plot(E, R, \"o\", label=\"data (œÉ/‚ü®E‚ü©)\")\n",
    "plt.plot(E_dense, R_fit, \"-\", label=f\"fit: a={a*100:.1f}%‚àöGeV, b={b*100:.2f}%\")\n",
    "plt.xlabel(\"Beam energy E (GeV)\")\n",
    "plt.ylabel(\"Energy resolution œÉ/‚ü®E‚ü©\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab3a9c-e0a2-463b-ba4e-a42c4becde83",
   "metadata": {},
   "source": [
    "Hey, congrats you made all the way through!  \n",
    "It‚Äôs okay if you don‚Äôt understand everything yet ‚Äî join the help session for some useful ideas.  \n",
    "Enjoy the process, stay curious, everything will be fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e908a9-72f0-4d9d-ad01-f11d1130b87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
