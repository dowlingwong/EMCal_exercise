{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b18b48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class KMeans:\n",
    "    \"\"\"\n",
    "    Minimal NumPy-only K-Means with functionized steps.\n",
    "    No sklearn, no typing â€” pure Python version.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "        Number of clusters (K).\n",
    "    init : {\"k-means++\", \"random\"}\n",
    "        Initialization scheme.\n",
    "    max_iter : int\n",
    "        Maximum iterations.\n",
    "    tol : float\n",
    "        Convergence tolerance on centroid shift (Euclidean norm).\n",
    "    random_state : int or None\n",
    "        Seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=None):\n",
    "        self.n_clusters = int(n_clusters)\n",
    "        self.init = init\n",
    "        self.max_iter = int(max_iter)\n",
    "        self.tol = float(tol)\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Attributes set after fitting\n",
    "        self.cluster_centers_ = None\n",
    "        self.labels_ = None\n",
    "        self.inertia_ = None\n",
    "        self.n_iter_ = None\n",
    "\n",
    "    # ---------- core primitives ----------\n",
    "\n",
    "    def _euclidean_squared(self, a, b):\n",
    "        \"\"\"\n",
    "        Squared Euclidean distances between rows of a (n_samples, d)\n",
    "        and rows of b (n_centroids, d). Returns (n_samples, n_centroids).\n",
    "        \"\"\"\n",
    "        a2 = np.sum(a * a, axis=1, keepdims=True)\n",
    "        b2 = np.sum(b * b, axis=1)\n",
    "        ab = a @ b.T\n",
    "        return a2 - 2.0 * ab + b2\n",
    "    \n",
    "    \n",
    "    def _kmeanspp_init(self, X, rng):\n",
    "        \"\"\"\n",
    "        k-means++ initialization. Returns (K, d) array of initial centroids.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        centroids = np.empty((self.n_clusters, n_features), dtype=X.dtype)\n",
    "\n",
    "        # 1) choose first centroid uniformly\n",
    "        idx0 = rng.integers(0, n_samples)\n",
    "        centroids[0] = X[idx0]\n",
    "\n",
    "        # 2) choose remaining with probability proportional to D^2\n",
    "        closest_dist_sq = self._euclidean_squared(X, centroids[0:1]).ravel()\n",
    "        for i in range(1, self.n_clusters):\n",
    "            probs = closest_dist_sq / closest_dist_sq.sum()\n",
    "            idx = rng.choice(n_samples, p=probs)\n",
    "            centroids[i] = X[idx]\n",
    "            d2 = self._euclidean_squared(X, centroids[i:i+1]).ravel()\n",
    "            closest_dist_sq = np.minimum(closest_dist_sq, d2)\n",
    "        return centroids\n",
    "\n",
    "    # ---------- step-by-step methods ----------\n",
    "    #rng = np.random.default_rng(42)\n",
    "    def _initialize_centroids(self, X, rng=None):\n",
    "        \"\"\"Step 2: Initialize centroids randomly.\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        # Set Python random seed if random_state was provided\n",
    "        if self.random_state is not None:\n",
    "            random.seed(self.random_state)\n",
    "        # Choose unique random indices for centroids\n",
    "        indices = random.sample(range(n_samples), self.n_clusters)\n",
    "        centroids = X[indices].copy()\n",
    "        return centroids\n",
    "\n",
    "    def _assign(self, X, centroids):\n",
    "        \"\"\"Step 3: Assignment â€” return (labels, d2).\"\"\"\n",
    "        d2 = self._euclidean_squared(X, centroids)\n",
    "        labels = np.argmin(d2, axis=1)\n",
    "        return labels, d2\n",
    "\n",
    "    def _update(self, X, labels, rng):\n",
    "        \"\"\"Step 4: Update â€” compute new centroids, handle empty clusters by re-seeding.\"\"\"\n",
    "        K, d = self.n_clusters, X.shape[1]\n",
    "        new_centroids = np.empty((K, d), dtype=float)\n",
    "        for j in range(K):\n",
    "            mask = (labels == j)\n",
    "            if np.any(mask):\n",
    "                new_centroids[j] = X[mask].mean(axis=0)\n",
    "            else:\n",
    "                # reinitialize empty cluster to a random point\n",
    "                new_centroids[j] = X[rng.integers(0, X.shape[0])]\n",
    "        return new_centroids\n",
    "\n",
    "    def _converged(self, old_centroids, new_centroids, old_labels, new_labels):\n",
    "        \"\"\"Step 5: Convergence check â€” label stability OR centroid shift < tol.\"\"\"\n",
    "        if old_labels is not None and np.array_equal(old_labels, new_labels):\n",
    "            return True\n",
    "        shift = float(np.sqrt(np.sum((new_centroids - old_centroids) ** 2)))\n",
    "        return shift < self.tol\n",
    "\n",
    "    def _compute_inertia(self, X, labels, centroids):\n",
    "        \"\"\"Step 6: Inertia (within-cluster SSE).\"\"\"\n",
    "        return float(np.sum((X - centroids[labels]) ** 2))\n",
    "\n",
    "    # ---------- public API ----------\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Run K-Means on X.\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "\n",
    "        centroids = self._initialize_centroids(X, rng)\n",
    "        labels = None\n",
    "\n",
    "        for it in range(1, self.max_iter + 1):\n",
    "            new_labels, _ = self._assign(X, centroids)\n",
    "            new_centroids = self._update(X, new_labels, rng)\n",
    "\n",
    "            if self._converged(centroids, new_centroids, labels, new_labels):\n",
    "                centroids = new_centroids\n",
    "                labels = new_labels\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "            labels = new_labels\n",
    "\n",
    "        # Final metrics\n",
    "        inertia = self._compute_inertia(X, labels, centroids)\n",
    "\n",
    "        # Set attributes\n",
    "        self.cluster_centers_ = centroids\n",
    "        self.labels_ = labels\n",
    "        self.inertia_ = inertia\n",
    "        self.n_iter_ = it\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Assign cluster indices for new samples using fitted centroids.\n",
    "        \"\"\"\n",
    "        if self.cluster_centers_ is None:\n",
    "            raise RuntimeError(\"Model is not fitted. Call .fit(X) first.\")\n",
    "        X = np.asarray(X, dtype=float)\n",
    "        labels, _ = self._assign(X, self.cluster_centers_)\n",
    "        return labels\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        \"\"\"\n",
    "        Convenience: fit the model and return labels for X.\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        return self.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ad8eeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Your KMeans ===\n",
      "Iterations: 7\n",
      "Inertia: 142.7541\n",
      "ARI vs true labels: 0.4290\n",
      "\n",
      "=== scikit-learn KMeans ===\n",
      "Iterations: 11\n",
      "Inertia: 78.8557\n",
      "ARI vs true labels: 0.7163\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans as SKKMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ---- Load Iris dataset ----\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y_true = iris.target\n",
    "\n",
    "# ---- Your implementation ----\n",
    "my_km = KMeans(n_clusters=3, init=\"k-means++\", max_iter=300, tol=1e-4, random_state=42)\n",
    "my_labels = my_km.fit_predict(X)\n",
    "\n",
    "print(\"=== Your KMeans ===\")\n",
    "print(f\"Iterations: {my_km.n_iter_}\")\n",
    "print(f\"Inertia: {my_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, my_labels):.4f}\")\n",
    "\n",
    "# ---- scikit-learn implementation ----\n",
    "sk_km = SKKMeans(n_clusters=3, init=\"k-means++\", n_init=1, max_iter=300, tol=1e-4,\n",
    "                 algorithm=\"lloyd\", random_state=42)\n",
    "sk_labels = sk_km.fit_predict(X)\n",
    "\n",
    "print(\"\\n=== scikit-learn KMeans ===\")\n",
    "print(f\"Iterations: {sk_km.n_iter_}\")\n",
    "print(f\"Inertia: {sk_km.inertia_:.4f}\")\n",
    "print(f\"ARI vs true labels: {adjusted_rand_score(y_true, sk_labels):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8546eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running KMeans standalone tests...\n",
      "  âœ“ test_basic_shapes_and_types\n",
      "  âœ“ test_determinism_with_seed\n",
      "  âœ“ test_predict_matches_training_assignment\n",
      "  âœ“ test_inertia_definition\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# test_kmeans_standalone_for_user_class.py\n",
    "# Standalone unit tests (no cornelltest) for a NumPy-only KMeans class.\n",
    "# Assumes a class named `KMeans` is importable from the current environment\n",
    "# (e.g., defined above in the same notebook/script, or from a module import).\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- Helper assertion functions ----------------\n",
    "\n",
    "def assert_equals(expected, actual, msg=None):\n",
    "    assert expected == actual, msg or f\"Expected {expected!r}, got {actual!r}\"\n",
    "\n",
    "def assert_not_equals(a, b, msg=None):\n",
    "    assert a != b, msg or f\"Did not expect {a!r} == {b!r}\"\n",
    "\n",
    "def assert_true(expr, msg=None):\n",
    "    assert bool(expr), msg or f\"Expression is not true: {expr!r}\"\n",
    "\n",
    "def assert_false(expr, msg=None):\n",
    "    assert not bool(expr), msg or f\"Expression is not false: {expr!r}\"\n",
    "\n",
    "def assert_floats_equal(expected, actual, tol=1e-6, msg=None):\n",
    "    if (isinstance(expected, float) and math.isnan(expected)) and (isinstance(actual, float) and math.isnan(actual)):\n",
    "        return\n",
    "    assert abs(expected-actual) <= tol, msg or f\"Expected {expected}, got {actual} (tol={tol})\"\n",
    "\n",
    "def assert_float_lists_equal(expected, actual, tol=1e-6, msg=None):\n",
    "    expected = np.asarray(expected, dtype=float)\n",
    "    actual = np.asarray(actual, dtype=float)\n",
    "    assert expected.shape == actual.shape, msg or f\"Shape mismatch: {expected.shape} vs {actual.shape}\"\n",
    "    diff = np.abs(expected - actual)\n",
    "    assert np.all(diff <= tol), msg or f\"Max diff {diff.max()} exceeds tol {tol}\"\n",
    "\n",
    "def rows_equal_any_permutation(A, B, tol=1e-8):\n",
    "    \"\"\"Return True if A and B contain the same rows up to permutation (within tol).\"\"\"\n",
    "    A = np.asarray(A, dtype=float)\n",
    "    B = np.asarray(B, dtype=float)\n",
    "    if A.shape != B.shape:\n",
    "        return False\n",
    "    used = np.zeros(B.shape[0], dtype=bool)\n",
    "    for i in range(A.shape[0]):\n",
    "        found = False\n",
    "        for j in range(B.shape[0]):\n",
    "            if not used[j] and np.allclose(A[i], B[j], atol=tol, rtol=0):\n",
    "                used[j] = True\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# ---------------- Tests for user's KMeans class ----------------\n",
    "\n",
    "try:\n",
    "    KMeans  # type: ignore\n",
    "except NameError:\n",
    "    try:\n",
    "        from kmeans import KMeans  # try local module named kmeans.py\n",
    "    except Exception as e:\n",
    "        raise ImportError(\n",
    "            \"Could not find KMeans in the current environment. \" \"Define your KMeans class above or ensure 'from kmeans import KMeans' works.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "def test_basic_shapes_and_types():\n",
    "    rng = np.random.default_rng(0)\n",
    "    X = np.vstack([\n",
    "        rng.normal([0,0], 0.2, size=(30,2)),\n",
    "        rng.normal([5,5], 0.2, size=(30,2)),\n",
    "        rng.normal([10,0], 0.2, size=(30,2)),\n",
    "    ])\n",
    "    km = KMeans(n_clusters=3, init=\"random\", random_state=123)\n",
    "    labels = km.fit_predict(X)\n",
    "\n",
    "    assert_equals(X.shape[0], labels.shape[0])\n",
    "    assert_equals((3, X.shape[1]), km.cluster_centers_.shape)\n",
    "    assert_true(km.inertia_ >= 0.0)\n",
    "    assert_true(isinstance(km.n_iter_, int) and km.n_iter_ >= 1)\n",
    "\n",
    "\n",
    "def test_determinism_with_seed():\n",
    "    rng = np.random.default_rng(1)\n",
    "    X = rng.normal(size=(100, 2))\n",
    "\n",
    "    km1 = KMeans(n_clusters=3, init=\"random\", random_state=7)\n",
    "    km2 = KMeans(n_clusters=3, init=\"random\", random_state=7)\n",
    "\n",
    "    labels1 = km1.fit_predict(X)\n",
    "    labels2 = km2.fit_predict(X)\n",
    "\n",
    "    assert_float_lists_equal(labels1, labels2, tol=0.0)\n",
    "    assert_true(rows_equal_any_permutation(km1.cluster_centers_, km2.cluster_centers_))\n",
    "\n",
    "\n",
    "def test_predict_matches_training_assignment():\n",
    "    rng = np.random.default_rng(2)\n",
    "    X = np.vstack([rng.normal([0,0], 0.3, size=(50,2)),\n",
    "                   rng.normal([4,4], 0.3, size=(50,2))])\n",
    "    km = KMeans(n_clusters=2, init=\"random\", random_state=9).fit(X)\n",
    "\n",
    "    d2 = ((X[:, None, :] - km.cluster_centers_[None, :, :])**2).sum(axis=2)\n",
    "    nearest = np.argmin(d2, axis=1)\n",
    "    assert_float_lists_equal(nearest, km.labels_, tol=0.0)\n",
    "\n",
    "    new_pts = np.array([[0.05, -0.02], [4.1, 3.9]])\n",
    "    preds = km.predict(new_pts)\n",
    "    d2_new = ((new_pts[:, None, :] - km.cluster_centers_[None, :, :])**2).sum(axis=2)\n",
    "    nearest_new = np.argmin(d2_new, axis=1)\n",
    "    assert_float_lists_equal(preds, nearest_new, tol=0.0)\n",
    "\n",
    "\n",
    "def test_inertia_definition():\n",
    "    rng = np.random.default_rng(3)\n",
    "    X = rng.normal(size=(80, 3))\n",
    "    km = KMeans(n_clusters=4, init=\"random\", random_state=11).fit(X)\n",
    "\n",
    "    d2 = ((X[:, None, :] - km.cluster_centers_[None, :, :])**2).sum(axis=2)\n",
    "    manual_inertia = float(np.sum(d2[np.arange(X.shape[0]), km.labels_]))\n",
    "    assert_floats_equal(km.inertia_, manual_inertia, tol=1e-8)\n",
    "\n",
    "\n",
    "def run_all_tests():\n",
    "    print(\"Running KMeans standalone tests...\")\n",
    "    test_basic_shapes_and_types()\n",
    "    print(\"  \\u2713 test_basic_shapes_and_types\")\n",
    "    test_determinism_with_seed()\n",
    "    print(\"  \\u2713 test_determinism_with_seed\")\n",
    "    test_predict_matches_training_assignment()\n",
    "    print(\"  \\u2713 test_predict_matches_training_assignment\")\n",
    "    test_inertia_definition()\n",
    "    print(\"  \\u2713 test_inertia_definition\")\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_all_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a3b92",
   "metadata": {},
   "source": [
    "Absolutely âœ… â€” hereâ€™s your content rewritten in **Markdown (MD)** format, ready to drop directly into a Jupyter Notebook section titled:\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ§© K-Means Clustering\n",
    "\n",
    "## What is Cluster Analysis?\n",
    "\n",
    "Cluster analysis is the process of **grouping together similar points into clusters**.\n",
    "A *point* can have 2, 3, or even hundreds of dimensions â€” meaning itâ€™s a vector in some space.\n",
    "\n",
    "One practical example is **epidemiological clustering**:\n",
    "you might have 2D points representing the **longitude and latitude** of locations where birds carrying different strains of avian flu were found.\n",
    "By clustering these points, you can gain insight into which regions correspond to each strain.\n",
    "\n",
    "---\n",
    "\n",
    "## Distances Between Points\n",
    "\n",
    "To cluster data, we must measure **how close or far** points are from each other.\n",
    "The **Euclidean distance** is the most common measure.\n",
    "\n",
    "For two 2D points:\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2}\n",
    "]\n",
    "\n",
    "For two 3D points:\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_x - q_x)^2 + (p_y - q_y)^2 + (p_z - q_z)^2}\n",
    "]\n",
    "\n",
    "In general, for two ( n )-dimensional points\n",
    "( p = (p_1, p_2, â€¦, p_n) ) and ( q = (q_1, q_2, â€¦, q_n) ):\n",
    "[\n",
    "d(p, q) = \\sqrt{(p_1 - q_1)^2 + (p_2 - q_2)^2 + \\cdots + (p_n - q_n)^2}\n",
    "]\n",
    "\n",
    "**Example:**\n",
    "[\n",
    "p = (0.1, 0.2, 0.3, 0.4), \\quad q = (0.0, 0.2, 0.3, 0.2)\n",
    "]\n",
    "[\n",
    "d(p, q) = \\sqrt{(0.1-0.0)^2 + (0.2-0.2)^2 + (0.3-0.3)^2 + (0.4-0.2)^2} = 0.7071â€¦\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "## Cluster Centroids\n",
    "\n",
    "The **centroid** of a cluster is its *center of mass* â€” the **average position** of all points in that cluster.\n",
    "\n",
    "Even though itâ€™s the mean of all cluster points, the centroid does **not** need to be one of those points.\n",
    "\n",
    "To compute a centroid:\n",
    "[\n",
    "\\text{centroid} = \\frac{1}{N} \\sum_{i=1}^{N} p_i\n",
    "]\n",
    "\n",
    "For points:\n",
    "[\n",
    "p + q = (p_1 + q_1, p_2 + q_2, â€¦, p_n + q_n)\n",
    "]\n",
    "and dividing by a scalar ( a ):\n",
    "[\n",
    "\\frac{p}{a} = \\left(\\frac{p_1}{a}, \\frac{p_2}{a}, â€¦, \\frac{p_n}{a}\\right)\n",
    "]\n",
    "\n",
    "---\n",
    "\n",
    "## The K-Means Algorithm\n",
    "\n",
    "The **idea** behind K-Means is simple:\n",
    "each point belongs to the cluster whose centroid (mean) it is **closest** to.\n",
    "\n",
    "However, because centroids depend on which points are assigned to them, and the assignments depend on the centroids â€” we solve this **chicken-and-egg** problem iteratively.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 1. Pick ( k ) Centroids\n",
    "\n",
    "We start by choosing ( k ), the number of clusters we want.\n",
    "\n",
    "Each centroid ( m_j ) is an ( n )-dimensional point:\n",
    "[\n",
    "m_j = (m_{j,1}, m_{j,2}, â€¦, m_{j,n})\n",
    "]\n",
    "\n",
    "We randomly select ( k ) points from the dataset as our **initial centroids**.\n",
    "This is known as the **Forgy Method**, and is one of the most common ways to initialize k-means.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 2. Partition the Dataset\n",
    "\n",
    "Each point is assigned to the **nearest centroid** based on Euclidean distance.\n",
    "\n",
    "If a point is equally close to two or more centroids, we break ties arbitrarily (usually by index order).\n",
    "\n",
    "This produces ( k ) sets ( S_1, S_2, â€¦, S_k ),\n",
    "where each set ( S_j ) contains all points closest to centroid ( m_j ).\n",
    "\n",
    "---\n",
    "\n",
    "### Step 3. Recompute the Means\n",
    "\n",
    "For each cluster ( S_j ), we recompute its centroid (mean):\n",
    "[\n",
    "m_j = \\frac{1}{|S_j|} \\sum_{q \\in S_j} q\n",
    "]\n",
    "\n",
    "That is, we take the average of all points assigned to that cluster.\n",
    "\n",
    "Since centroids have changed, some points may now be closer to a different centroid â€”\n",
    "so we **repeat the assignment step**.\n",
    "\n",
    "---\n",
    "\n",
    "### Step 4. Repeat Until Convergence\n",
    "\n",
    "We alternate between **assigning points** and **recomputing centroids** until:\n",
    "\n",
    "* The centroids stop moving, or\n",
    "* The assignments no longer change.\n",
    "\n",
    "This means the algorithm has **converged**.\n",
    "\n",
    "Sometimes convergence takes too long (many iterations).\n",
    "Therefore, we often set a **maximum iteration limit** to prevent infinite loops.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of the K-Means Algorithm\n",
    "\n",
    "1. Choose ( k ) and initialize centroids randomly.\n",
    "2. Assign each point to the nearest centroid.\n",
    "3. Recompute each centroid as the mean of its assigned points.\n",
    "4. Repeat steps 2â€“3 until centroids stop changing or max iterations reached.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… **Key Idea:**\n",
    "K-Means minimizes the **within-cluster sum of squared errors (inertia)** â€”\n",
    "that is, the total squared distance between points and their assigned centroids.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like me to add a small **Matplotlib visualization example** at the end of this Markdown (e.g., showing how centroids move across iterations on a 2D dataset)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47355746",
   "metadata": {},
   "source": [
    "### For particle physics, what tricks you can come up to reduce the computation complexity of number and coordination for the centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec82e56",
   "metadata": {},
   "source": [
    "### comparison of computational complexity for elbow and silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841b023",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
